Cursor Rules for Dynamo Project
https://github.com/keivenchang/dynamo-utils/blob/main/.cursorrules

=============================================================================
READ THIS FIRST (NON-NEGOTIABLE)
=============================================================================

If you do only one thing: re-read this section before making changes or running commands.

- Git commit policy (MUST):
  - NEVER suggest committing changes until the user explicitly asks
  - DO NOT proactively offer to commit, create commits, or ask "should I commit this?"
  - Wait for explicit user request like "commit this" or "create a commit"
  - This applies even after completing tasks - just report what was done, don't offer to commit

- Hugging Face usage (MUST):
  - DO NOT use Hugging Face libraries or APIs in new code unless explicitly requested
  - Avoid dependencies on transformers, datasets, accelerate, tokenizers, etc.
  - If existing code uses Hugging Face, do not add new Hugging Face dependencies
  - Prefer alternative solutions that don't require Hugging Face integration

- Pytest HF token (MUST):
  - Before running any `pytest`, do:
    - `export HF_HUB_OFFLINE=1 HF_TOKEN="$(cat ~/.cache/huggingface/token)" && pytest ...`
  - Prefer: `pytest --basetemp=/tmp/pytest_temp tests/`
  - Note: Only needed for existing tests that require HF authentication

- Cache deletion policy (MUST):
  - NEVER delete caches unless explicitly requested and permission is granted.
    - Examples: `__pycache__`, `.cache/`, `target/`, `node_modules/`, tmp dirs, etc.

- Shell execution (MUST):
  - Chain multi-step commands into ONE shell invocation using `&&` / `;` (reduce latency).
  - For expensive/long-running commands: capture FULL output first (`2>&1` to a file or `tee`).
    - Never pipe the live output of expensive commands into `grep`/`head`/`tail`.

- Python rules (MUST):
  - All imports at top of file. No `try/except` for imports. Never import inside functions.
  - Fail fast: do not hide errors (no blanket `except Exception:` unless re-raising).
  - No defensive `getattr()` for known typed attributes (use direct access).

=============================================================================
TABLE OF CONTENTS
=============================================================================
0. READ THIS FIRST (NON-NEGOTIABLE)
1. AI PERSONALITY AND DOCUMENTATION GUIDELINES
  1.1 AI Personality
  1.2 Documentation Guidelines
  1.3 Forbidden Jargon

2. BEST PRACTICES
  2.1 Security
  2.2 Performance and Optimization
  2.3 UNIX Command Execution and Workflow
    2.3.1 Command Chaining
    2.3.2 Long-Running Programs
    2.3.3 Piping and Filtering
    2.3.4 Waiting for Output (await_output.sh)
  2.4 Cron
    2.4.1 Environment and Variables
    2.4.2 Locks and Logging
    2.4.3 Editing crontab Safely
  2.5 Environment Awareness and Setup
    2.5.1 Virtualenv Activation (Host Machine Only)
    2.5.2 Docker Environment
      2.5.2.1 Setting umask for Group-Writable Permissions in Dockerfiles
      2.5.2.2 Example Dockerfile

3. UNIVERSAL CODE STYLE
  3.1 Emojis
  3.2 License Headers
  3.3 General Rules
  3.4 Rust Development
    3.4.1 Code Style
    3.4.2 File Organization
    3.4.3 Build Commands
    3.4.4 Type Inference for Examples
    3.4.5 Type Inference for lib/bindings/python
    3.4.6 Testing
    3.4.7 Error Handling
    3.4.8 Mutability Patterns
    3.4.9 Lock Management
    3.4.10 Dependency Management
    3.4.11 Python Bindings and Wheel Creation
  3.5 Python Development
    3.5.1 Code Style
    3.5.2 File Organization
    3.5.3 Error Handling
    3.5.4 Testing
  3.6 JavaScript/TypeScript
  3.7 Common Code Patterns
    3.7.1 Terminal Width Detection

4. UNIX/SHELL COMMANDS
  4.1 General Rules
  4.2 File Operations
  4.3 Permissions
  4.4 Path Display
  4.5 Pre-commit

5. GIT WORKFLOW
  5.1 Review Before Git Operations
  5.2 Merge Conflicts
  5.3 Commit Process
  5.4 Commit Message Format
  5.5 Git Integration (for parsing commit messages)

6. COMMUNICATION TEMPLATES AND CODE REVIEW
  6.1 Slack RFR Template
    6.1.1 GitHub to Slack Login Mappings
  6.2 GitHub PR Description Template
  6.3 Code Review Guidelines

7. DOCUMENTATION BUILD AND CI CHECKS
  7.1 Sphinx Documentation
    7.1.1 Overview
    7.1.2 Build Documentation
    7.1.3 Dependencies
    7.1.4 Smart Hyperlink Conversion
    7.1.5 Adding New Files
    7.1.6 Toctree Structure
    7.1.7 Build Warnings
    7.1.8 Checking Documentation Build
    7.1.9 Exclusions
  7.2 Pre-Merge CI Checks
    7.2.1 Rust Format Check
    7.2.2 Rust Clippy Checks
    7.2.3 Rust Tests
    7.2.4 Pre-commit Hooks
    7.2.5 Copyright Headers
    7.2.6 Cargo Deny (License Checks)
    7.2.7 Quick Pre-Commit Checklist

=============================================================================
1. AI PERSONALITY AND DOCUMENTATION GUIDELINES
=============================================================================

## 1.1 AI Personality
- Be direct, matter-of-fact, and honest about technical challenges
- Don't be overly agreeable or sycophantic
- Suggest alternatives when current approach has issues
- Ask clarifying questions when requirements are unclear
- CRITICAL: When debugging or fixing code, FIRST check what exists in main branch
  - Remove any extra tests/code that weren't in main or explicitly requested
  - Don't waste time debugging things that shouldn't exist
  - Only work on what was explicitly asked for
- Reproduce with a single concrete input (one job id / one log file / one failing command) before generalizing.
- Before changing code, re-read the exact region you‚Äôre editing; keep edits tightly scoped to avoid stale-context patch failures.

## 1.2 Documentation Guidelines
Always add comments for:
- Complex algorithms
- Business logic
- API endpoints
- Configuration options
- Non-obvious code decisions

Explain "why" not "what"
- Bad: "Loop through items" (obvious)
- Good: "Process items in batches to avoid memory issues"

## 1.3 Forbidden Jargon
DO NOT use these BS words in docs/comments:
- intuitive, comprehensive, optimal, seamless
- next-generation, holistic, cutting-edge

=============================================================================
2. BEST PRACTICES
=============================================================================

## 2.1 Security
- Never commit API keys or secrets
- Use environment variables for config
- Validate all user inputs
- Use parameterized queries for databases
- Follow principle of least privilege

## 2.2 Performance and Optimization
- Profile before optimizing
- Use appropriate data structures
- Consider memory allocation patterns
- Use async/await for I/O
- Cache expensive computations
- Monitor resource usage in production

**CRITICAL: CACHE DELETION POLICY**
- **NEVER EVER delete caches unless explicitly requested and granted permission**
- This includes but is not limited to:
  - Python `__pycache__` directories
  - Build caches (cargo target/, node_modules/, etc.)
  - Application caches (.cache/, tmp/, etc.)
  - Any other cached data or temporary files
- Always ask for explicit permission before deleting any cache
- Deleting caches without permission can break workflows and cause unnecessary rebuilds

## 2.3 UNIX Command Execution and Workflow

### 2.3.1 Command Chaining
**ALWAYS chain multiple independent commands into a single Shell call using && or ;**

**CRITICAL RULE: If you're about to make 2+ separate Shell tool calls in sequence, STOP and chain them instead!**

- Use parentheses for grouping: (command1 && command2); (command3 || command4)
- Separate outputs with echo "=====" for readability
- Examples:
  - (cd dir && command1 && echo "=====" && command2 && echo "=====" && ...)
  - (grep keyword1 file && echo "=====" && grep keyword2 file && echo "=====" && grep keyword3 file && ...)
  - command1; must_run_command2; must_run_command3
  - (cd dir1 && cargo fmt); (cd dir2 && cargo fmt)
  - (rg pattern1 file | wc -l && echo "=====") && (rg pattern2 file | wc -l && echo "=====") && rg pattern3 file
- **Why this matters:**
  - Reduces latency from multiple round-trips to one
  - More efficient use of tool calls
  - Easier to read consolidated output
- Be careful with shell quoting in long one-liners (especially nested quotes). Prefer simpler, verifiable commands (or write a small script) over clever quoting.

### 2.3.2 Long-Running Programs
- For long-running programs (vllm, sglang, trtllm), use tee to log output to a file and background it
- Do NOT filter output using grep - everything must be visible in the log file
- Format: program args 2>&1 | tee /tmp/program.log &
- Example: vllm serve 2>&1 | tee /tmp/vllm.log &
- Prefer a stable filename (same path) so it‚Äôs easy to `tail -f` (e.g. `/tmp/output1.log`)
- This allows monitoring while keeping the terminal responsive
- Do NOT use `-it` in scripts/background jobs (non-interactive runs will fail with `the input device is not a TTY`)
- If you want to `tail -f`, write to a stable log path (e.g. `/tmp/output1.log`) and tail that file (don‚Äôt invent per-run filenames unless requested)

### 2.3.3 Piping and Filtering
**CRITICAL BEST PRACTICE: For long-running or expensive commands, ALWAYS capture the full, unprocessed output first (to a temp file) and only filter that saved file afterward.**

**Correct pattern (ALWAYS use this):**
```bash
command > /tmp/output.txt 2>&1 &
# or for interactive monitoring:
command 2>&1 | tee /tmp/output.txt &
```

**ABSOLUTE RULES:**
- ‚úÖ **DO:** Redirect the ENTIRE, UNPROCESSED output to a temp file (or `tee` it)
- ‚úÖ **DO:** Background long-running commands with `&`
- ‚úÖ **DO:** Capture both stdout and stderr with `2>&1`
- ‚ùå **NEVER:** Pipe the output of long-running/expensive commands into `grep`, `head`, `tail`, or similar filters
- ‚ùå **NEVER:** Lose information by filtering before saving the full output

**Why:**
- Run the command ONCE and analyze the full output multiple times
- Preserves ALL information - no data loss
- Allows multiple different analyses on the saved file
- You can grep/head/tail the temp file without re-running the command

**Examples:**
- `docker ps -a > /tmp/containers.txt` ‚úÖ (NOT `docker ps -a | grep something` ‚ùå)
- `cargo test > /tmp/test.txt 2>&1 &` ‚úÖ (NOT `cargo test | grep PASS` ‚ùå)
- `kubectl get pods > /tmp/pods.txt` ‚úÖ (NOT `kubectl get pods | head -20` ‚ùå)
- Don‚Äôt assume tools exist (e.g. `rg`). Prefer Cursor search/`grep`; if an external binary is needed, check for it first (`command -v rg`).

When reviewing saved logs, filter out unimportant cargo test output (on the saved file, not the live command output):
- Example: `grep -v -E "running 0 tests|test result: ok\\. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out|tower_http::trace::on_failure:" /tmp/test.txt`
- "running 0 tests"
- "test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out"
- "tower_http::trace::on_failure:"

### 2.3.4 Waiting for Output (await_output.sh)

**NEVER use `sleep N && command && grep 'DONE'` ‚Äî it always waits the full sleep duration.**

Use `_/await_output.sh` instead. It runs the command, streams output, and exits immediately
when a sentinel string appears (or on timeout). All output is logged to a file regardless.

**Usage:**
```bash
_/await_output.sh -t TIMEOUT -s "SENTINEL" [-s "SENTINEL2" ...] [-l LOGFILE] [-q] -- COMMAND [ARGS...]
```

- `-t, --timeout SECONDS` ‚Äî maximum wait time (**required**, no default)
- `-s, --sentinel STRING` ‚Äî string to watch for (repeatable; exits on first match)
- `-l, --log FILE` ‚Äî log file path (default: `/tmp/await_output.log`)
- `-q, --quiet` ‚Äî suppress terminal output (log only)

**Exit codes:** 0 = sentinel found, 1 = usage error, 2 = timeout, 3 = command exited without sentinel

**Examples:**

Single command:
```bash
_/await_output.sh -t 90 -s "model loaded" -- python serve.py
```

Series of commands (wrap in `bash -c`):
```bash
_/await_output.sh -t 120 -s "BUILD COMPLETE" -- bash -c 'cargo build && cargo test && echo "BUILD COMPLETE"'
```

Multiple sentinels (first match wins):
```bash
_/await_output.sh -t 60 -s "listening on" -s "READY" -s "model loaded" -- ./start_server.sh
```

**Why this matters:**
- `sleep 60 && grep DONE` always waits 60s even if DONE appears at 3s
- `await_output.sh` exits at 3s, saving 57s per invocation
- Output is always captured to a log file for later inspection
- Timeout ensures the script never hangs forever

## 2.4 Cron

### 2.4.1 Environment and Variables
- Cron does **not** source `~/.bashrc` by default. If you need tokens, source an explicit env file or use `bash -lc '...'`.
- Cron runs with a minimal environment; do not assume variables like `USER` exist.
  - If scripts use `set -u`, never reference `$USER` directly; use a fallback (`${USER:-${LOGNAME:-$(id -un)}}`).
- Cron variable assignments are **not a full shell**:
  - Avoid relying on nested expansion like `DYNAMO_UTILS=$NVIDIA_HOME/...`.
  - Avoid relying on `$HOME` expansion inside assignments.
  - Prefer absolute paths in the crontab for anything critical.

### 2.4.2 Locks and Logging
- If a cron job skips due to a lock, print a warning (stderr) with the lock path. Silent skips look like ‚Äúcron isn‚Äôt running‚Äù.
- Prefer stable, dated log directories so you can prove ‚Äúcron ran‚Äù by checking mtimes and tailing files.

### 2.4.3 Editing crontab Safely
- Cron path edits: `crontab -l` often contains literal strings like `$HOME/...` (not expanded). When replacing paths, match the literal text, then verify with `crontab -l | grep`.
- Avoid overly clever one-liner awk/sed edits to crontab; write the transform to a temp file or script so quoting doesn‚Äôt break and you can diff the output.

## 2.5 Environment Awareness and Setup
- Prefer robust behavior under bad environments:
  - Handle ‚Äúpoisoned‚Äù env vars/tokens deterministically (don‚Äôt silently pick the wrong credential source).
  - Keep core diagnostic modules runnable via a small CLI so you can test on a single file quickly.

### 2.5.1 Virtualenv Activation (Host Machine Only)
- At the start of each context, check if on host machine (not in Docker)
- If on host: activate the project venv (path varies by machine); if inside Docker, it's already activated.
- This ensures pre-commit and other Python tools are available
- Detection: Check if running in container by looking for /.dockerenv or checking hostname
- When debugging "a generated HTML page is not showing/updating in the browser":
  - Verify the on-disk file exists, permissions, and timestamp: `ls -lah <file> && stat <file> && head -n 10 <file>`
  - Confirm your web server docroot matches the filesystem path you‚Äôre editing (URL path ‚â† filesystem path).
  - If you regenerate output but still see old content, hard refresh / bypass cache, and verify mtime changed.
  - If grepping generated HTML, remember it may contain escaped text (e.g. `"` becomes `&quot;`), so match the escaped form or inspect the raw log.
  - If ‚Äúit worked earlier‚Äù, verify you‚Äôre not looking at a cached artifact: check mtimes and any cache index/state the generator uses.

### 2.5.2 Docker Environment
- Multi-stage builds for smaller images
- Set appropriate user permissions
- Use .dockerignore
- Pin dependency versions
- When one script delegates to another (e.g. build wrappers), do not re-derive values in the callee; pass through the computed values for parity.
- For BuildKit features, remember named contexts (`--build-context name=path`): missing passthrough can cause `COPY --from=<name>` to try pulling an image.

#### 2.5.2.1 Setting umask for Group-Writable Permissions in Dockerfiles

To create group-writable files/directories (775/664) in Dockerfiles:

**Global umask for RUN commands:**
```dockerfile
USER myuser
# Set umask globally for all subsequent RUN commands
RUN mkdir -p /etc/profile.d && echo 'umask 002' > /etc/profile.d/00-umask.sh
SHELL ["/bin/bash", "-l", "-o", "pipefail", "-c"]

# Now all RUN commands automatically use umask 002
RUN mkdir /test  # Creates drwxrwxr-x (775)
RUN touch /file  # Creates -rw-rw-r-- (664)
```

**CRITICAL: COPY does NOT respect umask!**
- The `COPY` instruction bypasses shell umask and always creates destination directories with 755
- The `--chmod` flag on COPY only affects contents, NOT the destination directory itself
- You MUST use explicit `chmod g+w` after COPY to fix the destination directory

Pattern for COPY with group-writable permissions:
```dockerfile
COPY --chmod=775 --chown=user:0 /source /dest
RUN chmod g+w /dest  # Required! COPY ignores umask and creates /dest as 755
```

Summary:
- ‚úÖ umask works for: RUN mkdir, RUN touch, pip install output files, etc.
- ‚ùå umask does NOT work for: COPY destination directories
- Solution: Use both umask (for RUN) and explicit chmod (after COPY)

#### 2.5.2.2 Example Dockerfile
```
FROM rust:1.70 as builder
WORKDIR /app
COPY . .
RUN cargo build --release

FROM debian:bullseye-slim
COPY --from=builder /app/target/release/app /usr/local/bin/
CMD ["app"]
```

#### 2.5.2.3 Container Permission Optimization (runtime/dev/local-dev)

Key rules (learned from debugging slow builds + permission issues):
- Terminology (be precise):
  - **Stages** refer to Dynamo container build targets: `--target` (e.g. `runtime`, `dev`, `local-dev`).
  - **Frameworks** refer to the LLM engine selection: `--framework` (same thing), typically one of: `none`, `vllm`, `sglang`, `trtllm`.
- Avoid recursive chmod/chown on large trees (e.g. `chmod -R g+w /workspace`, `chown -R ...`) ‚Äî they can add minutes.
- Prefer targeted, non-recursive permission fixes for the minimal runtime-writable directories:
  - `/home/dynamo` (user home)
  - `/home/dynamo/.cache` (uv/pip cache)
  - `/opt/dynamo` (runtime scratch files like `.launch_screen`)
  - `/workspace` (workspace writability)
- Use a three-tier container approach when possible:
  - `runtime`: production, minimal permissions, runs as `dynamo`
  - `dev`: development with extra tools, often root (use with caution)
  - `local-dev`: maps to host UID/GID for local development
- Always sanity-check permission changes:
  - For **runtime** images: `sanity_check.py --runtime-check-only --thorough`
  - For **dev/local-dev** images: `sanity_check.py --thorough`
- Monitor build times when adding permission operations; treat them as performance-sensitive code.

=============================================================================
3. UNIVERSAL CODE STYLE
=============================================================================

## 3.1 Emojis
- DO NOT use emojis (unprofessional)
- Rare exceptions only: ‚úÖ üö´ ‚ùå ‚ö†Ô∏è

## 3.2 License Headers
- Use first 2 lines only:
```
// SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
// SPDX-License-Identifier: Apache-2.0
```

## 3.3 General Rules
- Don't remove TODO comments or commented lines below them
- Don't generate *.md files unless explicitly requested
- Verify HTML/markdown links work before adding them
- When editing via apply-patch: hunks must be top-to-bottom ordered and match current file context; if a patch fails, re-read the relevant region and re-apply with narrower, accurate context (don‚Äôt guess line blocks).

Dashboards / CI log work (recent learnings):
- **Scope discipline:** If the user says ‚Äúonly `dynamo-utils.dev/`‚Äù, do not read or modify `dynamo-utils/` (prod). Keep changes isolated to the requested tree.
- **Flags/CLI reality check:** Before running a script with flags (especially `update_html_pages.sh`), run `--help` to confirm the flag exists (e.g., `--fast` was removed; `--fast-debug` is the supported fast mode).
- **Context plumbing:** If you want logs to include commit SHA everywhere, ensure the caller passes `commit_sha`/PR `head_sha` into the pipeline; adding `{commit_ref}` in the logger isn‚Äôt enough if the upstream call supplies `""`.
- **Append-only logs:** When verifying ‚Äúevery line is prefixed‚Äù, remember old content in an append-only log won‚Äôt be retroactively fixed. Verify against newly appended lines (or rotate/truncate explicitly if required).

## 3.4 Rust Development

### 3.4.1 Code Style
- snake_case for variables/functions
- PascalCase for types/traits
- Use explicit types when it improves readability
- Add doc comments (///) for public APIs
- Prefer tracing::error over eprintln
- Prefer shorter references: `MyStuff` instead of `crate::my_service::MyStuff`
- Prefer .to_string() over format!() when possible
- Prefer positive if/else: `if x then A else B` not `if !x then B else A`
  - Exception: `if !x then A` (without else) is fine
- Use debug_assert* over assert*

### 3.4.2 File Organization
- lib.rs: Library entry point
- mod.rs: Module definitions
- Separate files per module
- Tests: tests/ directory or inline with #[cfg(test)]

### 3.4.3 Build Commands
- Always use --locked: cargo test --locked, cargo build --locked, cargo install --locked
- Development build: cargo build --locked --features dynamo-llm/block-manager --workspace
- Clean builds: cargo clean
- Before commit: cargo fmt (run on all affected directories)
- See section 7.2 (Pre-Merge CI Checks) for comprehensive build/test/lint commands

### 3.4.4 Type Inference for Examples
Add to top-level Cargo.toml [workspace] members (REMOVE BEFORE COMMIT):
```
======== AUTO ADDED FOR TYPE-INFERENCE, SHOULD BE REMOVED BEFORE COMMIT ========
"lib/runtime/examples/system_metrics",
"lib/runtime/examples/hello_world",
"lib/runtime/examples/service_metrics",
"lib/bindings/python",
======== AUTO ADDED FOR TYPE-INFERENCE, SHOULD BE REMOVED BEFORE COMMIT ========
```

### 3.4.5 Type Inference for lib/bindings/python
1. Add "lib/bindings/python" to top-level Cargo.toml [workspace] members (see above)
3. Comment out [workspace] in lib/bindings/python/Cargo.toml:
```
======== WORKSPACE DECLARATION REMOVED FOR TYPE-INFERENCE, RESTORE BEFORE COMMIT ========
[workspace]
# empty workspace to exclude from top level workspace
# excluded due to pyo3 extension module build issues
======== WORKSPACE DECLARATION REMOVED FOR TYPE-INFERENCE, RESTORE BEFORE COMMIT ========
```
4. Add empty integration feature to lib/bindings/python/Cargo.toml (if not present):
```
[features]
default = []
block-manager = ["dynamo-llm/block-manager", "dep:dlpark", "dep:cudarc"]
integration = []  # Empty feature for rust-analyzer compatibility
```
5. Restart rust-analyzer (Cmd/Ctrl+Shift+P ‚Üí "Rust Analyzer: Restart Server")
6. IMPORTANT: Restore all changes before committing

### 3.4.6 Testing
- Write unit tests in same file (unless told otherwise)
- Use #[cfg(test)] for test-only code
- Mock external dependencies when mocks are available
- Integration tests use --features integration: cargo test --locked --features integration -- --nocapture
- Specific integration test: cargo test --locked -p dynamo-runtime --features integration --lib http_server -- --nocapture
- During tests, show progress if building/compiling
- List which tests failed (up to 10) and pass/fail breakdown (unit vs integration)
- For DistributedRuntime/Runtime/drt tests: use unique names (ns515, comp515, ep515)
  - See lib/runtime/src/metrics.rs for examples

### 3.4.7 Error Handling
- Use Result<T, E> for fallible operations
- Use Option<T> for nullable values
- Prefer ? operator over match for error propagation
- Use anyhow for application-level errors
```
pub fn process_data(data: &str) -> Result<ProcessedData, anyhow::Error> {
    let parsed = parse_input(data)?;
    let result = transform_data(parsed)?;
    Ok(result)
}
```

### 3.4.8 Mutability Patterns
Limit scope of mutable variables:
```
// Instead of:
let mut mut_var = ...;
mut_var.some_mutable_operation();
// ... mut_var used all over

// Do this:
let var = {
    let mut mut_var = ...;
    mut_var.some_mutable_operation();
    mut_var
};
```

### 3.4.9 Lock Management
Release locks before long operations:
```
// Bad:
let reg = self.registry.lock().unwrap();
if let Some(entry) = reg.get(name) {
    entry.execute_long_call()  // holds lock too long
}

// Good:
let long_call = {
    let reg = self.registry.lock().unwrap();
    reg.get(name).clone()
}; // Lock released here
long_call()
```

### 3.4.10 Dependency Management
Validate dependency updates:
- See `7.2.6 Cargo Deny (License Checks)` for the canonical commands.

### 3.4.11 Python Bindings and Wheel Creation
After changes in lib/bindings/python/rust/*:
1. cd lib/bindings/python && maturin develop --uv
3. Or use _/compile.sh shortcut (handles full build workflow)

Notes:
- `maturin develop` may update `Cargo.lock` if the dependency graph/features require it.
- Decide intentionally: allow lockfile updates for local iteration, or require locked builds (`--locked`) and commit the lockfile update once.

## 3.5 Python Development

### 3.5.1 Code Style

**CRITICAL RULES (NEVER VIOLATE WITHOUT EXPLICIT PERMISSION):**

1. **ALL IMPORTS AT TOP OF FILE - NO try/except - NEVER INSIDE FUNCTIONS**
   - ‚ùå NEVER: `def foo(): import json`
   - ‚ùå NEVER: `try: import requests; HAS_REQUESTS = True; except: HAS_REQUESTS = False`
   - ‚úÖ ALWAYS: Import directly at module top: `import requests`
   - Import third-party packages DIRECTLY - don't use try/except to hide ImportError
   - Fail fast if dependencies are missing (add them to requirements.txt)
   - Exception: ONLY with explicit user permission for lazy imports in rare cases

2. **NO DEFENSIVE getattr() WHEN TYPES ARE KNOWN**
   - ‚ùå NEVER: `getattr(node, "job_name", "")` when node has job_name
   - ‚úÖ ALWAYS: `node.job_name` (let it fail if attribute missing!)
   - Using getattr() for known attributes is REDUNDANT and hides bugs

3. **FAIL FAST - NEVER HIDE ERRORS**
   - ‚ùå NEVER: `try: ... except Exception: pass`
   - ‚ùå NEVER: `try: ... except Exception as e: logging.error(...); return []`
   - ‚úÖ ALWAYS: Let exceptions propagate immediately
   - ‚úÖ ONLY catch specific exceptions you can actually handle
   - See detailed examples in section 3.5.3 below

**Standard Style Rules:**
- Follow PEP 8
- Check indentation carefully (must be perfect)
- **Indentation/continuation-indent MUST be mechanically verified after edits (don't rely on eyeballing):**
  - **Single-command indentation gate (preferred):**
    - `python3 py_indent_report.py --only-problems <touched_py_files>`
      - This **subsumes** both:
        - `python3 -tt -m py_compile ...` (hard syntax/indent gate)
        - `python3 -m tabnanny ...` (mixed tabs/spaces / ambiguous indent)
      - Example: `python3 py_indent_report.py --only-problems dynamo-utils/html_pages/common_dashboard_lib.py`
    - Optional: `python3 py_indent_report.py --self-check` (verifies the detector catches common mistakes like mis-indented `else:` blocks).
    - **Escalation rule:** If you (the AI) keep introducing indentation errors, run `py_indent_report.py` **after each meaningful edit chunk** until the errors stop.
    - **CRITICAL:** When fixing indentation errors, always read 20‚Äì30 lines of surrounding context and fix the whole block (not just the one flagged line). Adjacent lines often share the same mistake.
    - **Common mistake:** Over-indenting the first ‚Äúreal‚Äù statement after a comment (comment/code must align).
  - If you touched many files/dirs and want a fast parse-only pass:
    - `python3 -m compileall -q <touched_dirs_or_files>`
  - **Auto-fix formatting + indentation (preferred):**
    - `ruff format <touched_paths>`
  - **Lint (and auto-fix what it can):**
    - `ruff check --fix <touched_paths>`
  - If `.pre-commit-config.yaml` exists in the repo you're working in, prefer:
    - `pre-commit run --files <touched_files>` (or `pre-commit run --all-files` for broad changes)
- Use dataclass for dicts with >4 elements (better type inference)
- Use simple regex for multi-line string manipulations
- snake_case for variables/functions
- PascalCase for classes
- Add type hints where beneficial
- Use docstrings for functions/classes
- Before commit: run mypy and ruff (or pre-commit ruff, if configured)
- 3+ print statements: use triple quotes """ ... """
- Outside Docker: source ~/bin/$(uname).$(uname -m)/venv.3.*/bin/activate

### 3.5.2 File Organization
- __init__.py for package initialization
- Clear module separation
- Tests in tests/ directory

### 3.5.3 Error Handling and Anti-Patterns

**CRITICAL: FAIL FAST - NEVER HIDE ERRORS**

**THIS IS AN ABSOLUTE RULE - NO EXCEPTIONS WITHOUT EXPLICIT USER PERMISSION**

Hiding errors makes debugging impossible and creates bugs that will need fixing later. Every error-hiding pattern below is FORBIDDEN:

```python
# ‚ùå ABSOLUTELY FORBIDDEN:
try:
    something()
except Exception:
    pass  # NEVER DO THIS - Silent failure!

# ‚ùå ABSOLUTELY FORBIDDEN:
try:
    something()
except Exception as e:
    logging.error(f"Error: {e}")  # NEVER DO THIS - Log and hide!
    # Missing raise = hidden error!

# ‚ùå ABSOLUTELY FORBIDDEN:
try:
    something()
except Exception as e:
    print(f"Error: {e}")  # NEVER DO THIS - Print and continue!
    continue

# ‚ùå ABSOLUTELY FORBIDDEN:
try:
    something()
except Exception:  # NO NO NO!!!!!! DO NOT DO THIS!
    return []  # NEVER DO THIS - Return default on error!

# ‚ùå ABSOLUTELY FORBIDDEN:
try:
    something()
except Exception as e:
    logger.error(f"Failed: {e}")
    return None  # NEVER DO THIS - Hide error with return!
```

**WHY THESE ARE FORBIDDEN:**
- Makes debugging impossible (where did the error happen?)
- Hides bugs until production
- Wastes hours tracking down issues later
- Corrupts data by continuing with invalid state
- The user EXPLICITLY WANTS errors to fail immediately

**ALWAYS FAIL EARLY AND LOUDLY**

```python
# ‚úÖ DO THIS - Let exceptions propagate:
result = something()  # If it fails, let it crash!

# ‚úÖ DO THIS - Only catch SPECIFIC exceptions you can handle:
try:
    result = parse_config(file)
except FileNotFoundError:
    # Specific exception we know how to handle
    result = DEFAULT_CONFIG
except ValueError as e:
    # Another specific exception we can handle
    logger.warning(f"Invalid config format: {e}")
    result = DEFAULT_CONFIG
# Other exceptions propagate up!

# ‚úÖ DO THIS - Re-raise after logging if you can't handle it:
try:
    result = something()
except Exception as e:
    logger.error(f"Failed to do something: {e}")
    raise  # Re-raise so caller knows it failed!
```

**CRITICAL: NEVER USE `except Exception:` WITHOUT RE-RAISING**

‚ùå **ABSOLUTELY FORBIDDEN:**
```python
# Catching Exception without re-raising = hiding ALL errors!
try:
    something()
except Exception:
    pass  # HIDES ALL ERRORS!

try:
    something()
except Exception as e:
    logger.error(f"Error: {e}")  # HIDES ERROR FROM CALLER!
    # Missing raise = silent failure

try:
    something()
except Exception:
    return []  # HIDES ERROR WITH DEFAULT VALUE!
```

‚úÖ **CORRECT - Use SPECIFIC exception types:**
```python
# Catch only exceptions you know how to handle:
try:
    result = json.loads(text)
except json.JSONDecodeError as e:
    logger.error(f"Invalid JSON: {e}")
    return {}  # OK: specific exception, intentional handling

try:
    file_size = os.path.getsize(path)
except FileNotFoundError:
    file_size = 0  # OK: specific exception, intentional default

try:
    value = int(string)
except ValueError:
    value = 0  # OK: specific exception, intentional default
```

**WHY `except Exception:` IS ALMOST ALWAYS WRONG:**
- Catches **everything**: ValueError, TypeError, AttributeError, KeyError, etc.
- Hides bugs you didn't anticipate
- Makes debugging impossible ("where did the error come from?")
- Violates fail-fast principle

**THE RULE:**
1. If you can remove the try/except ‚Üí DO IT (let it fail fast!)
2. If you must catch exceptions ‚Üí Use SPECIFIC types (FileNotFoundError, ValueError, TypeError, etc.)
3. If you catch Exception ‚Üí You MUST re-raise it (or have explicit user permission)

**Why this matters:**
- Silent failures make debugging impossible
- They hide bugs until production
- They corrupt data by continuing with partial/invalid state
- They waste hours of debugging time looking in the wrong places

**If you're tempted to catch and ignore:**
1. Ask: "Can I actually handle this error gracefully?"
2. If yes: Handle it specifically
3. If no: DON'T CATCH IT - let it fail fast!

Regex / parsing changes (common source of subtle bugs):
- Be very careful with escaping:
  - In Python raw strings, `\s` is whitespace; `\\s` is a literal backslash + `s` (often wrong).
- When changing a critical regex, add a tiny local one-line reproduction/"unit test" to prove the match works on representative input.

**CRITICAL ANTI-PATTERN: NO REDUNDANT getattr() WHEN TYPES ARE KNOWN**

**ABSOLUTE RULE: If you know the object has an attribute, access it directly - NO getattr()!**

‚ùå **ABSOLUTELY FORBIDDEN (when types are known):**
```python
# If node is typed and has job_name attribute:
getattr(node, "job_name", "")  # REDUNDANT - you already know it has job_name!
str(getattr(node, "job_name", "") or "")  # REDUNDANT and hides None bugs!
getattr(node, "job_name", None) or ""  # REDUNDANT defensive garbage!

# If pr is typed PRInfo:
getattr(pr, "number", 0)  # REDUNDANT - pr.number exists!
```

‚úÖ **CORRECT (direct attribute access):**
```python
# Type is known, attribute exists - just use it!
node.job_name
str(node.job_name)
pr.number
```

**WHY getattr() IS FORBIDDEN FOR KNOWN ATTRIBUTES:**
- REDUNDANT - you already know the attribute exists from types
- Masks AttributeError bugs that should fail immediately
- Makes type checkers (mypy/pyright) completely useless
- Hides None/empty string confusion
- Defensive programming just delays finding real bugs
- The user EXPLICITLY wants immediate failures, not defensive hiding

**ONLY EXCEPTION - Unknown/Dynamic Attributes:**
Use getattr() ONLY for truly optional/dynamic attributes on duck-typed objects:
```python
# OK for optional attributes:
if hasattr(node, "optional_field"):
    value = node.optional_field  # Direct access after hasattr check!

# OK for dynamic plugin-style attributes:
handler = getattr(self, f"handle_{event_type}", None)
if handler:
    handler()
```

**NEVER use getattr() as a "safe" way to access known attributes - that's what type hints are for!**

### 3.5.4 Testing
- Framework: pytest
- Unit tests in tests/ directory
- Use fixtures for common setup
- Mock external services
- Before running any `pytest`: see `READ THIS FIRST (NON-NEGOTIABLE)` for the required `HF_TOKEN` export pattern.
- Always use: pytest --basetemp=/tmp/pytest_temp tests/

### 3.5.5 Dynamo-utils dashboards + log categorization

See `dynamo-utils/README.md` (Dashboards / log categorization pitfalls) for dashboard-specific learnings and gotchas. Keep `.cursorrules` focused on coding conventions and mechanical checks.

## 3.6 JavaScript/TypeScript
- camelCase for variables/functions
- PascalCase for components/classes
- Prefer const over let, avoid var
- Use async/await over .then() chains
- Add JSDoc comments for complex functions

## 3.7 Common Code Patterns

### 3.7.1 Terminal Width Detection
```
from common import get_terminal_width
width = get_terminal_width()  # Fallback to 80 if detection fails
```

=============================================================================
4. UNIX/SHELL COMMANDS
=============================================================================

## 4.1 General Rules
- Source .bashrc when shell starts (interactive shells). Cron jobs do **not** load `~/.bashrc` unless you explicitly source it.
- Never use "!" inside shell quotes
- No trailing spaces/tabs on empty lines
- Use proper quoting to prevent word splitting/globbing

## 4.2 File Operations
- Check if file is under git before moving
- Use git mv for tracked files, mv for untracked
- Delete *.lock files instead of stashing
- Do not edit `.gitignore` unless explicitly requested (prefer leaving local-only scripts untracked or placing them under `/tmp/`)
- Dedup safely: use hashes/diffs + reference search before deleting duplicates.
- Symlinks: do **not** create ‚Äúconvenience‚Äù symlinks by default (they clutter). Only add symlinks when explicitly requested or when a stable link is truly required for compatibility.
- When moving scripts, preserve history with `git mv`, ensure executable bits survive (`chmod +x`), and run a quick smoke test.

## 4.3 Permissions
```
USER_ID=$(stat -c "%u" .)
GROUP_ID=$(stat -c "%g" .)

# üö® DO NOT DO THIS:
# NEVER run recursive permission fixes on large trees (very slow, and easy to break things):
#   chown -R $USER_ID:$GROUP_ID .
#
# Prefer targeted, non-recursive fixes on only the specific directories you need writable.
# Examples:
#   chown $USER_ID:$GROUP_ID /path/to/dir
#   chown $USER_ID:$GROUP_ID /path/to/file
#   find /path/to/dir -maxdepth 1 -type d -name 'target' -exec chown $USER_ID:$GROUP_ID {} \;
```

- If you add a new `.sh` script that is meant to be executed, ensure it has a shebang and is executable (`chmod +x`) before committing.
- Permission-aware discovery: when scanning the filesystem (repos, logs, etc.), gate on permissions (e.g. world `r+x`) so dashboards don‚Äôt try to traverse private dirs.

## 4.4 Path Display
- Use tilde (~) instead of full paths: ~/path not /home/ubuntu/path

## 4.5 Pre-commit
ALWAYS run pre-commit checks before committing:
- For single file: pre-commit run --files <file_path>
- For all changed files: pre-commit run --all-files
- Pre-commit runs automatically on git commit, but run manually to catch issues early
- Fix any issues reported before committing

=============================================================================
5. GIT WORKFLOW
=============================================================================

## 5.1 Review Before Git Operations
Periodically review this .cursorrules before git operations
- Don‚Äôt assume the current working directory is a git repo. Confirm repo root first (`git rev-parse --show-toplevel`) or use `git -C <dir> ...` for the intended repo.

## 5.2 Git Interactive Editors
- Git commands like `git rebase --continue`, `git commit --amend`, and `git rebase -i` launch interactive text editors (vim/nano)
- Cursor does NOT have interactive editor
- Therefore ALWAYS use `GIT_EDITOR=true` prefix to bypass interactive editors:
  - `GIT_EDITOR=true git rebase --continue` - accepts default commit message
  - `GIT_EDITOR=true git commit --amend -m "message"` - amends with new message
  - For commits, use `-m "message"` flag instead of letting editor open
- If editor opens accidentally, the command will hang waiting for user input
- Example: `git rebase --continue` will open vim ‚Üí use `GIT_EDITOR=true git rebase --continue` instead

## 5.3 Merge Conflicts
After resolving:
1. git add <resolved_files>
   - You MUST `git add` each conflict-resolved file to mark it as resolved (merge/rebase/cherry-pick).
   - Forgetting to `git add` after conflict resolution will cause the operation to fail or repeat conflicts.
2. If in rebase: use `GIT_EDITOR=true git rebase --continue` (never let vim open)
3. Run cargo fmt on directories

## 5.4 Commit Process
- NEVER launch vim or any editor (always provide -m flag with message)
- Don‚Äôt suggest committing unless the user explicitly says to commit.
- Never commit top-level Cargo.toml or Cargo.lock (unless explicitly told)
- Never use --no-verify
- Signoff rules:
  - In dynamo-utils repository: --signoff is NOT required
  - In dynamo* repositories and /workspace: ALWAYS use --signoff (never skip it)
- Run cargo fmt before committing Rust changes
- Never add untracked files (unless explicitly told)
- List untracked files separately from modified files
- Prompt to git add modified files
- Scope commits when asked: keep reorganizations, code changes, and docs changes as separate commits.
- **BEFORE writing commit message:** Check `git log --oneline origin/main..HEAD`
  - Empty output = FIRST commit = Use verbose format with prefix
  - Shows commits = SUBSEQUENT commit = Use terse format without prefix
- Diff changes and generate appropriate message based on commit position
- For merge commits: use git commit -m "Merge ..." or git commit --no-edit

## 5.5 Commit Message Format

**CRITICAL: Determine commit type BEFORE writing the message**
1. Check if branch has existing commits: `git log --oneline origin/main..HEAD`
2. If output is EMPTY ‚Üí This is the FIRST commit ‚Üí Use INITIAL format
3. If output shows commits ‚Üí This is a SUBSEQUENT commit ‚Üí Use SUBSEQUENT format

### FIRST/INITIAL COMMIT (when branch has NO commits yet)
**Format:** Verbose with category prefix (feat:, fix:, docs:, etc.)
**Length:** Full descriptive sentence
**Examples:**
- feat: add new user authentication system
- fix: resolve memory leak in data processing
- docs: update API documentation
- test: add unit tests for user module
- ci: configure continuous integration pipeline
- refactor: reuse code for better maintenance and readability
- perf: optimize data processing for speed
- chore: update dependencies and clean up
- revert: undo previous commit due to issues
- style: apply code formatting and style fixes
- build: update build scripts for new environment

### SUBSEQUENT COMMITS (when branch ALREADY has commits)
**Format:** Terse, no prefix, straight to the point
**Length:** 1 line preferred, 2 lines maximum
**Examples:**
- Quick fix of the module in XYZ
- Documentation updates on XYZ
- Minor changing the usage of XYZ
- Renaming of XYZ to ZYX
- Remove leftover merge conflict marker
- Fix linting errors
- Address review comments
- Update test assertions

**DO NOT DO (subsequent commits):**
- ‚ùå Use category prefixes (save these for the FIRST commit):
  - feat: ...
  - fix: ...
  - refactor: ...
- ‚ùå Use WIP / placeholder messages:
  - WIP
  - tmp
  - stuff
- ‚ùå Write a multi-paragraph commit message (put details in the PR description instead)
- ‚ùå Restate the entire PR purpose (the FIRST commit already does that)

**Why this matters:** The first commit establishes the PR's primary purpose and shows up in git history. Subsequent commits are implementation details that get squashed during merge.

## 5.6 Git Integration (for parsing commit messages)
- Format: `title (#PR_NUMBER)`
- Extract PR: r'\(#(\d+)\)'
- GitHub repo: https://github.com/ai-dynamo/dynamo
- Use full SHA for URLs, short SHA (7-9 chars) for display

=============================================================================
6. COMMUNICATION TEMPLATES AND CODE REVIEW
=============================================================================

## 6.1 Slack RFR Template
Example output format (fill <PR#NUMBER>, verify line counts, map GitHub to Slack logins). If <PR#NUMBER> is unknown, ask.
```
RFR (code: +123/-55 lines, documents: 50 lines changed):
*feat:* DIS-3456 some feature desc here
*PR:* http://github.com/ai-dynamo/dynamo/pull/<PR#NUMBER>
*Reviewers:* <top 3 reviewers based on past commits>, @Ryan McCormick, ...
```
Then add 3 terse bullets about the PR
Output in plain text surrounded by triple backticks

### 6.1.1 GitHub to Slack Login Mappings
- rmccormick -> @Ryan McCormick
- kthui -> @Jacky Hui
- nv-tusharma, tusharma ‚Üí @Tushar Sharma
- ishandhanani ‚Üí @Ishan Dhanani
- anant-s ‚Üí @Anant Sharma
- hhzhang16 ‚Üí @Hannah Zhang
- grahamk ‚Üí @Graham King
- krish ‚Üí @Krishnan Prashanth
- yanrpei ‚Üí @Rudy Pei
- biswa.panda ‚Üí @Biswa Ranjan Panda
- tedzhouhk ‚Üí @Hongkuan Zhou
- tzulingk ‚Üí @Tzu-Ling Kan
- neelays ‚Üí @Neelay Shah
- tanmayv25 ‚Üí @Tanmay Verma

If 0 document lines changed, omit "documents: ..." section
Never show literal <PR#NUMBER>, ask if unknown

## 6.2 GitHub PR Description Template
Look at chain of continuous commits from same author
Output in plain text surrounded by triple backticks (no formatting):
```
#### Overview:

<!-- 2-3 terse sentences based on commits -->

#### Details:

<!-- Bullet points describing changes -->

#### Where should the reviewer start?

<!-- Specific files to review closely -->

#### Related Issues: (use Closes / Fixes / Resolves / Relates to)

<!-- Linear ticket (DIS-1123, DYN-1789, OPS-4321) extracted from commits, or leave blank -->

/coderabbit profile chill
```

## 6.3 Code Review Guidelines
- Review for security vulnerabilities
- Check for performance issues
- Ensure proper error handling
- Verify test coverage
- Look for code duplication
- Check adherence to conventions

- When providing review feedback, prefer short, direct, conversational paragraphs.
- Output in plain text surrounded by triple backticks (no formatting).
- For structural changes (like big code refactors, Dockerfiles, shared build scripts, or cross-file patterns), call out both:
  - what the author did well and why it works (or what it enables), and
  - disadvantages, if any (e.g. complexity, readability, maintainability)
- For shared/duplicated sections that must stay in sync across files (e.g., `dynamo_base`, `wheel_builder`, `dynamo_runtime` in `Dockerfile.{vllm,trtllm,sglang}`), explicitly suggest:
  - adding comments near those sections noting they must stay synchronized, and
  - considering templating instead of code-duplication to avoid code drift and maintenance nightmare
- It's preferred to phrase colloquial feedback like this:
  - "Hey Dillon, thank you for restructuring the framework Dockerfiles to use that same dynamo_base, dynamo_runtime, and wheel_builder flow so that various pieces are built once and then reused/cached later."
  - "You may want to put a big comment in shared targets (e.g. dynamo_base, wheel_builder, dynamo_runtime, etc), saying that they need to be in-sync between all the Dockerfile.{vllm,trtllm,sglang} files. Otherwise, somebody is going to get lazy, modify only one file, and mess something up. Definitely look into templating."
  - "The tradeoff to optimization is that the stage graph is now pretty hard to follow. I find it really hard to follow this code now, unless I ask AI to give me a dependency/flow chart like the one below. Maybe we could add the dependency/flow chart next to the code, for better understanding. The AI can sync it up pretty easily."
  - "Looking forward to get this in, it will be good to have ..."

=============================================================================
7. DOCUMENTATION BUILD AND CI CHECKS
=============================================================================

## 7.1 Sphinx Documentation

### 7.1.1 Overview
- Source: docs/ directory
- Build output: docs/build/html/
- Main script: docs/generate_docs.py

### 7.1.2 Build Documentation
```
cd ~/dynamo
python docs/generate_docs.py
```
Steps: make clean ‚Üí preprocess_docs() ‚Üí make html

### 7.1.3 Dependencies
```
pip install sphinx sphinx-rtd-theme myst-parser
```

### 7.1.4 Smart Hyperlink Conversion
docs/generate_docs.py converts links automatically:
- GitHub URLs ‚Üí relative paths (for .md files in docs/)
  Example: https://github.com/ai-dynamo/dynamo/blob/main/docs/guides/metrics.md ‚Üí ../../guides/metrics.md
- Relative paths ‚Üí GitHub URLs (for non-.md or outside docs/)
  Example: ../examples/config.pbtxt ‚Üí https://github.com/ai-dynamo/dynamo/blob/main/examples/config.pbtxt

### 7.1.5 Adding New Files
1. Place file in appropriate subdirectory (docs/backends/*)
3. Add to docs/hidden_toctree.rst (for backend docs not in main TOC)
   Example: backends/sglang/prometheus.md
4. Use relative paths (script handles conversion)
5. Test: python docs/generate_docs.py

### 7.1.6 Toctree Structure
- docs/index.rst: Main index
- docs/_sections/*.rst: Section indexes
- docs/hidden_toctree.rst: Hidden toctree for files not in main TOC
- Backend docs order: TensorRT-LLM, SGLang, vLLM

### 7.1.7 Build Warnings
Sphinx uses -W flag (warnings = errors)
- Missing toctree entries cause failures
- All .md files must be referenced in a toctree
- Check for: "WARNING: document isn't included in any toctree"
- Invalid JSON in code blocks marked as ```json will cause lexer errors
  - Either fix JSON syntax (remove ellipsis ..., comments, etc.)
  - Or change to ```text if non-valid JSON content is intentional

### 7.1.8 Checking Documentation Build
Test locally before pushing (replicates CI environment):
```
cd /path/to/dynamo/repo
docker build -t docs-builder -f container/Dockerfile.docs .
```
Expected: "build succeeded" with no warnings
If fails: Check for missing images, broken links, invalid JSON in code blocks

### 7.1.9 Exclusions
Files in docs/exclusions.txt are skipped during hyperlink conversion

## 7.2 Pre-Merge CI Checks
Run all the checks that CI runs before merging. These commands replicate the
CI environment locally.

Quick checklist before commit:
- See `7.2.7 Quick Pre-Commit Checklist` (single canonical checklist).

### 7.2.1 Rust Format Check
Check code formatting (must pass before commit):

cargo fmt -- --check

Check all directories that CI checks:
(cd . && cargo fmt -- --check)
(cd lib/bindings/python && cargo fmt -- --check)
(cd lib/runtime/examples && cargo fmt -- --check)
(cd launch/dynamo-run && cargo fmt -- --check)

Fix formatting:
cargo fmt

### 7.2.2 Rust Clippy Checks
Find unused imports, warnings, and other issues:

cargo clippy --no-deps --all-targets -- -D warnings

Check all directories that CI checks:
(cd . && cargo clippy --no-deps --all-targets -- -D warnings)
(cd lib/bindings/python && cargo clippy --no-deps --all-targets -- -D warnings)
(cd lib/runtime/examples && cargo clippy --no-deps --all-targets -- -D warnings)
(cd launch/dynamo-run && cargo clippy --no-deps --all-targets -- -D warnings)

Find specific issues:
cargo clippy --no-deps --all-targets -- -D warnings > /tmp/clippy.txt 2>&1
grep -B 5 -A 10 "unused import" /tmp/clippy.txt
grep -E "^(error|warning)" /tmp/clippy.txt

### 7.2.3 Rust Tests
Run all tests (unit, doc, integration):

Compile tests first (separate build from execution):
cargo test --locked --no-run

Run doc tests (CI runs doc generation first):
cargo doc --no-deps && cargo test --locked --doc

Run unit tests (--all-targets doesn't run doc tests):
cargo test --locked --all-targets

NOTE: CI runs tests in these directories: ., lib/bindings/python, lib/runtime/examples, launch/dynamo-run

Backend E2E serve tests (aggregated, single-GPU):

pytest tests/serve/ -k "aggregated and not disagg" -v --tb=short

Note: Avoid using -k "aggregated" alone because it also matches "disaggregated".
Always use the combined filter "aggregated and not disagg" so only aggregated tests run.

### 7.2.4 Pre-commit Hooks
Run all pre-commit hooks (Python linting, formatting, etc.):

pre-commit run --all-files
pre-commit run --files path/to/file.py
pre-commit run ruff --all-files
pre-commit run mypy --all-files

Common hooks: ruff (Python linter), mypy (type checking), trailing-whitespace,
end-of-file-fixer, check-yaml, check-json

### 7.2.5 Copyright Headers
Check copyright headers (requires PowerShell):

pwsh .github/workflows/copyright-check.ps1

Or manually check:
grep -L "SPDX-FileCopyrightText" $(find . -name "*.rs" -o -name "*.py" -o -name "*.go")

### 7.2.6 Cargo Deny (License Checks)
Check licenses and security advisories:

cargo-deny --version || cargo install cargo-deny@0.16.4
cargo-deny --no-default-features check --hide-inclusion-graph licenses bans --config deny.toml

### 7.2.7 Quick Pre-Commit Checklist
Before committing Rust changes, run:
- Prefer a single chained command (with separators) so it‚Äôs one copy/paste and one log stream.

Rust-only (auto-fix formatting first):
```bash
cargo fmt && echo "=====" && cargo clippy --no-deps --all-targets -- -D warnings && echo "=====" && cargo test --locked --all-targets
```

Rust + Python changes:
```bash
cargo fmt && echo "=====" && cargo clippy --no-deps --all-targets -- -D warnings && echo "=====" && cargo test --locked --all-targets && echo "=====" && pre-commit run --all-files
```

If scripts or HTML generators changed: `python3 -m py_compile <touched_py_files>` and run the relevant generator/update script to validate end-to-end output.

Expected result: All checks pass with no errors

