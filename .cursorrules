# Keiven's Cursor Rules for Dynamo Project
# This file helps guide AI behavior when working with this codebase
# https://github.com/keivenchang/dynamo-utils/blob/main/.cursorrules

# =============================================================================
# PROJECT OVERVIEW
# =============================================================================
# This is a Rust-based and Python-based project with Python bindings and web components
# The project uses cargo for Rust builds, uv for Python package management, and Docker for containerization
# You will re-read this file from time to time to refresh your memory.
#
# Key project components:
# - Rust runtime and core libraries
# - Python bindings via maturin
# - Web components and interfaces
# - Docker containerization support
# - Code in `lib/llm/src/http/...` are considered "frontend"
# - Code in `lib/llm/src/http/service/metrics.rs` is considered frontend metrics
# - Code in `components/backends/...` are backend component framework code
# - Code in `lib/runtime/src/system_status_server.rs` is for the backend component code serving metrics
# - Don't generate a *.md file unless I ask for it
# - If inside the Docker container, then
#   - tensorrt_llm lib codes are in bin/ext/tensorrt_llm/...
#   - vllm lib codes are in bin/ext/vllm/...
#   - sglang lib codes are in bin/ext/sglang/...

# =============================================================================
# AI PERSONALITY AND BEHAVIOR
# =============================================================================
# - Do not be overly agreeable, sycophantic, and use too many positive words
# - Be as a matter of fact, direct, and honest about technical challenges
# - Suggest alternatives when current approach has issues
# - Ask clarifying questions when requirements are unclear

# =============================================================================
# UNIVERSAL CODE STYLE RULES
# =============================================================================
# All code style (*.md, Python, bash, Rust, etc...)
# - Emojis are childish looking and extremely unprofessional. Do NOT use them.
# - If absolutely necessary, the exceptions are: ‚úÖ, üö´, ‚ùå, ‚ö†Ô∏è for rare exceptions.
# - We only need the first 2 lines of the license. Full text not needed. For example:
```
// SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
// SPDX-License-Identifier: Apache-2.0
```
# - Don't remove TODO comments or the commented lines below it
# - When adding HTML or md references, always double check that the link works.

# =============================================================================
# RUST DEVELOPMENT GUIDELINES
# =============================================================================

## Code Style
# - Use snake_case for variables and functions
# - Use PascalCase for types and traits
# - Prefer explicit types over type inference when it improves readability
# - Add doc comments (///) for public APIs
# - Use clippy for linting: cargo clippy
# - Prefer `tracing::error` over `eprintln`
# - When possible, use a shorter reference like `MyStuff` instead of `crate::my_service::MyStuff`
# - Prefer `.to_string()` over use of `format!`
# - Prefer the positive if/else statements. For example, use `if True then A else B` instead of `if not True then B else A`
# - The exception is that if there is a `if not True then A` (without the else), then that is fine. I don't ever want to see `if not True then pass else A`

## File Organization
# Rust files should be organized as:
# - lib.rs: Main library entry point
# - mod.rs: Module definitions
# - Separate files for each module
# - Tests in tests/ directory or inline with #[cfg(test)]

## Build Commands and Rules
# - For all cargo test, cargo build, and cargo install, make sure to add `--locked`
# - Test changes with: `cargo test --locked`
# - Use `cargo clean` if you encounter build issues
# - For running "build and test" CI, run (without using tail):
```
bash -ec 'rustup component add rustfmt clippy && \
              cargo fmt -- --check && \
              cargo clippy --features block-manager --no-deps --all-targets -- -D warnings && \
              (cd lib/bindings/python && cargo clippy --features block-manager --no-deps --all-targets -- -D warnings) && \
              cargo test --locked --all-targets --features=block-manager && \
              cargo test --locked --features integration -- --nocapture'
```

## Formatting and Linting
# - Run `cargo fmt` whenever there are significant changes to Rust (*.rs files)
# - Also periodically run `cargo clippy --no-deps --all-targets -- -D warnings`
# - Also periodically run `(cd lib/bindings/python && cargo clippy --no-deps --all-targets -- -D warnings)`

## Type Inference for Examples
# When working on any example directories in "lib/runtime/examples/<dir>" or "lib/bindings/python":
# - Look at the top level Cargo.toml file, in the [workspace] members section
# - And insert the temporary content below, in order to allow rust-analyzer to perform type inference:
```
    # ======== AUTO ADDED FOR TYPE-INFERENCE, SHOULD BE REMOVED BEFORE COMMIT ========
    "lib/runtime/examples/system_metrics",
    "lib/runtime/examples/hello_world",
    "lib/runtime/examples/service_metrics",
    "lib/bindings/python",
    # ======== AUTO ADDED FOR TYPE-INFERENCE, SHOULD BE REMOVED BEFORE COMMIT ========
```

## Type Inference for lib/bindings/python specifically
# To enable rust-analyzer type inference for lib/bindings/python/rust/* files:
# 1. In top-level Cargo.toml, add "lib/bindings/python" to [workspace] members:
```
    # ======== AUTO ADDED FOR TYPE-INFERENCE, SHOULD BE REMOVED BEFORE COMMIT ========
    "lib/bindings/python",
    # ======== AUTO ADDED FOR TYPE-INFERENCE, SHOULD BE REMOVED BEFORE COMMIT ========
```
# 2. In lib/bindings/python/Cargo.toml, comment out the [workspace] section:
```
    # ======== WORKSPACE DECLARATION REMOVED FOR TYPE-INFERENCE, RESTORE BEFORE COMMIT ========
    # [workspace]
    # # empty workspace to exclude from top level workspace
    # # excluded due to pyo3 extension module build issues
    # ======== WORKSPACE DECLARATION REMOVED FOR TYPE-INFERENCE, RESTORE BEFORE COMMIT ========
```
# 3. In lib/bindings/python/Cargo.toml, add empty integration feature (if not present):
```
    [features]
    default = []
    block-manager = ["dynamo-llm/block-manager", "dep:dlpark", "dep:cudarc"]
    # Empty feature to satisfy rust-analyzer when workspace has integration feature enabled
    integration = []
```
# 4. Restart rust-analyzer (Cmd/Ctrl+Shift+P ‚Üí "Rust Analyzer: Restart Server")
# 5. IMPORTANT: Restore all changes before committing (marked with comment delimiters)

## Testing Guidelines
# - Write unit tests in the same file as the code unless told otherwise
# - Use `#[cfg(test)]` for test-only code
# - Mock external dependencies when mocks are available
# - When integration tests are mentioned, it means to use `--features integration`
#   - Example: `cargo test --locked --features integration ... -- --nocapture`
# - For specific integration tests, add the "--lib <name>" flag:
#   - Example: `cargo test --locked -p dynamo-runtime --features integration --lib http_server -- --nocapture`
# - Example integration test command:
```
cargo test --locked -p dynamo-runtime --features integration test_metricsregistry_trait::test_drt_nats_metrics -- --nocapture
```
# - To run ALL the integration tests (only when asked explicitly):
```
cargo test --locked --features integration -- --nocapture
```
# - When asked to run a test, check whether it's inside a feature
#   - For example, if test_xyz is inside an integration feature marked as: `#[cfg(feature = "integration")]`
#   - Then make sure to run like this:
```
cargo run ... --features integration --lib mod_name::test_xyz ...
```
# - During tests, if it is building/compiling, then show the progress
# - When running tests, always list which tests failed (up to 10), and number of passed/failed broken down by unit vs. integration tests
# - When creating new tests related to DistributedRuntime/Runtime/drt, make sure to name all the Namespace, Component, and Endpoints with unique names that do not exist anywhere else in the code base, like: ns515, comp515, ep515. The tests in lib/runtime/src/metrics.rs offer examples.

## Error Handling
# - Use Result<T, E> for fallible operations
# - Use Option<T> for nullable values
# - Prefer ? operator over match for error propagation
# - Use anyhow for application-level error handling
# Example:
```
pub fn process_data(data: &str) -> Result<ProcessedData, anyhow::Error> {
    let parsed = parse_input(data)?;
    let result = transform_data(parsed)?;
    Ok(result)
}
```

## Mutability Patterns
# If a mut_var is used all over the place:
# ```Rust
# let mut mut_var = ...;
# mut_var.some_mutable_operation();
# // and mut_var is used all over the code, which is undesirable...
# ```
# Then try to limit the scope of var with this pattern:
# ```Rust
# let var = {
#   let mut mut_var = ...;
#   mut_var.some_mutable_operation();
#   mut_var;
# };
# ```

## Lock Management
# - If a call is known to take a while, then make the lock scope shorter
# For example, instead of the following long call after a lock:
```
let reg = self.registry.lock().unwrap();
if let Some(entry) = regi.get(name) {
    entry.execute_long_call()  // this will hold the lock very long
}
```
# Do this instead:
```
let long_call = {
    let reg = self.registry.lock().unwrap();
    reg.get(name).clone()
}; // Lock released here
long_call()
```

## Assertions and Debugging
# - `debug_assert*` calls are preferred over `assert_*`

## Dependency Management
# When Rust dependencies are updated, validate with:
# - (cargo-deny --version || cargo install --locked cargo-deny@0.16.4)
# - (cargo-deny --no-default-features check --hide-inclusion-graph licenses bans --config deny.toml)

## Python Bindings
# If you make any changes in lib/bindings/python/rust/* make sure you run `maturin develop`

## Wheel Creation Rules
# When asked to create Python wheel, do the followings, in fewer steps (combined steps using "&&" in shell), when possible:
# - cargo build --locked --features dynamo-llm/block-manager --workspace
# - If Python bindings changed, run: (cd lib/bindings/python && maturin develop)
# - If uv errors or not installed:
#   - install via the command: uv pip install maturin[patchelf]

# =============================================================================
# PYTHON DEVELOPMENT GUIDELINES
# =============================================================================

## Code Style
# - Follow PEP 8 conventions
# - When importing, try to put the imports on top of the file. Don't put it inside def.
# - Always double check the indentation of your code changes; in Python it must be perfect, not over or under-indent
# - If creating a new dict with more than 4 elements, prefer using dataclass for better type inference
# - For string manipulations that take a couple of lines, try to use simple regex instead to reduce lines
# - Use snake_case for variables and functions
# - Use PascalCase for classes
# - Add type hints where beneficial
# - Use docstrings for functions and classes
# - Before any Python commit, always run through: mypy and precommit ruff
# - If there are 3 or more print statements, tidy up and use the triple quote method, like: """ <code here> """
# - If you're not in Docker, try to execute this virtualenv first: `source ~/bin/$(uname).$(uname -m)/venv.3.*/bin/activate`

## File Organization
# Python files should follow:
# - __init__.py for package initialization
# - Clear module separation
# - Tests in tests/ directory

## Error Handling
# - Use try/except for exception handling
# - Raise specific exceptions rather than generic ones
# - Use context managers (with statements) for resource management
# Example:
```
def process_file(filename: str) -> None:
    try:
        with open(filename, 'r') as f:
            data = f.read()
        process_data(data)
    except FileNotFoundError:
        logger.error(f"File {filename} not found")
        raise
```

## Testing Guidelines
# - Use pytest for testing framework
# - Write unit tests in tests/ directory
# - Use fixtures for common test setup
# - Mock external services
# - Always pass `--basetemp=/tmp/pytest_temp` to avoid cluttering project root with test artifacts
#   Example: `pytest --basetemp=/tmp/pytest_temp tests/`

## End-to-End (E2E) Backend Testing with Metrics Validation
# - E2E tests validate backend deployments with comprehensive metrics validation
# - Tests validate both dynamo_component_* metrics (‚â•23 unique) and backend-specific metrics
# - Backend-specific metric thresholds:
#   - vLLM: ‚â•52 unique vllm:* metrics (80% of ~65 typical metrics)
#   - SGLang: ‚â•20 unique sglang:* metrics (80% of ~25 typical metrics)
#   - TensorRT-LLM: ‚â•4 unique trtllm:* metrics (80% of ~5 typical metrics)

## Aggregated vs Disaggregated Mode Requirements
# - **Aggregated mode**: Single GPU deployment, all components on one device
#   - Works with single GPU systems
#   - Requires metrics server: `DYN_SYSTEM_ENABLED=true DYN_SYSTEM_PORT=8081`
#   - Example: vLLM and SGLang aggregated configs include metrics validation
# - **Disaggregated mode**: Multi-GPU deployment, prefill/decode separation
#   - Requires multiple GPUs (typically 2+ GPUs)
#   - Will fail on single GPU systems with service discovery errors
#   - Use aggregated mode for single GPU testing and metrics validation

# Individual backend E2E tests (aggregated configs with metrics validation):
```
pytest tests/serve/test_vllm.py::test_serve_deployment -k "aggregated" -v --tb=short
pytest tests/serve/test_sglang.py::test_sglang_deployment -k "aggregated" -v --tb=short
pytest tests/serve/test_trtllm.py::test_deployment -k "aggregated" -v --tb=short
```

# All backend E2E tests with metrics validation:
```
pytest tests/serve/ -k "aggregated" -v --tb=short
```

# Filtered output (recommended to avoid clutter):
```
pytest tests/serve/ -k "aggregated" -v --tb=short | grep -v "running 0 tests" | grep -v "test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out" | grep -v "tower_http::trace::on_failure:"
```

# All serve tests (requires GPU resources):
```
pytest tests/serve/ -v --tb=short
```

## Metrics Server Configuration for Backend Tests
# - Backend launch scripts must include metrics server environment variables for E2E tests
# - **Required environment variables**:
#   - `DYN_SYSTEM_ENABLED=true` - Enables the metrics server
#   - `DYN_SYSTEM_PORT=8081` - Sets metrics endpoint port (default: 8081)
# - **Example launch script pattern**:
```bash
# run worker with metrics enabled
DYN_SYSTEM_ENABLED=true DYN_SYSTEM_PORT=8081 \
python -m dynamo.backend_name --model <model> [other_args]
```
# - **Backend-specific examples**:
#   - vLLM: `/workspace/components/backends/vllm/launch/agg.sh` (already configured)
#   - SGLang: `/workspace/tests/serve/launch/sglang_agg.sh` (updated to include metrics)
#   - TensorRT-LLM: Launch scripts should follow same pattern
# - **Without metrics server**: Tests will fail with "Connection refused" on port 8081

# =============================================================================
# JAVASCRIPT/TYPESCRIPT DEVELOPMENT GUIDELINES
# =============================================================================

## Code Style
# - Use camelCase for variables and functions
# - Use PascalCase for components and classes
# - Prefer const over let, avoid var
# - Use async/await over .then() chains
# - Add JSDoc comments for complex functions

# =============================================================================
# UNIX/SHELL COMMANDS AND GUIDELINES
# =============================================================================

## General Shell Rules
# - When Cursor UNIX shell starts, source the .bashrc
# - Do not EVER use "!" (exclamation marks) inside shell quotes
# - When adding an empty line, do not add trailing spaces or tabs
# - Use proper quoting to prevent word splitting and globbing issues

## File Operations
# - When moving files, check if a file is under git
# - If it's under git, then use `git mv <src_file> <dest_file>` instead of plain mv
# - If it's not under git, then go ahead with `mv ...` command
# - There is no reason to stash *.lock files, you can just delete them when needed

## Permission Management
# If there are permission problems, make sure the uid/gid are correct:
```
USER_ID=$(stat -c "%u" .)
GROUP_ID=$(stat -c "%g" .)
chown -R $USER_ID:$GROUP_ID .
```

## Piping and Filtering
# - When running `cargo test ...`:
#   - filter out unimportant lines using `grep -v` on the followings:
#      `running 0 tests`
#      `test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out`
#      `tower_http::trace::on_failure:`

## Multi-directory Commands
# - When asked to `cargo fmt`, do this in one step:
```
(cd $DYNAMO_HOME/lib/runtime/examples && cargo fmt); (cd $DYNAMO_HOME/lib/bindings/python && cargo fmt); (cd $DYNAMO_HOME && cargo fmt)
```

## Pre-commit command
# - Before commit, run a pre-commit

## Using ~ instead of the full path
# - When executing full paths, understand the $HOME
# - Use the tilde (~) to make the output nicer. For example, `~/path` is preferred over `/home/ubuntu/path` and preferred over `$HOME/path`.


# =============================================================================
# BUILD AND DEVELOPMENT WORKFLOW
# =============================================================================

## Key Build Commands
# - cargo build --locked: Build Rust components
# - uv build: Build Python packages
# - maturin build: Build Python extensions

# =============================================================================
# GIT WORKFLOW AND COMMIT GUIDELINES
# =============================================================================

## Cursor Rules -- periodically review this .cursorrules before any git operation

## Merge Conflicts
# After git merge conflicts are resolved, perform:
# 1. `git add <file(s)>` where the resolved <file(s)>
# 2. see if you're inside a git rebase operation. If so, let the user perform `git rebase --continue`. Don't open terminal by yourself because Cursor gets stuck.
# 3. Then, `cargo fmt` on a series of directories in one shot

## Commit Process
# - Never git add or commit top level Cargo.toml nor Cargo.lock, unless explicitly told to.
# - Never ever commit using `--no-verify`, I don't want that to appear, ever.
# - When git commit, always include a signoff using the `git commit --signoff ...` in the command.
# - When committing Rust changes, make sure to run through the `cargo fmt` (on a bunch of directories) first.
#   - Never ever add untracked files, unless explicitly told
#   - List untracked files on the same line. Then separately, list all the files that were modified and will be committed
#   - Prompt if I want to `git add` these modified files
#   - Then diff through the changes since the last commit and then generate a message that describes the changes.
#   - If the change is straightforward, a single line message is preferred

## Commit Message Format
# - When I say "commit", make it terse, 1 if a small commit, or at most a couple of lines,if it helps with clarity. Something like:
#   quick fix of the module in XYZ ...
#   documentation updates on XYZ ...
#   minor, changing the usage of XYZ to perform something else like ...
#   renaming of XYZ to ZYX ...
# - The one exception is that when I say "first commit" or "initial commit", follow the format below, on the very first line of the message:
#   feat: add new user authentication system
#   fix: resolve memory leak in data processing
#   docs: update API documentation
#   test: add unit tests for user module
#   ci: configure continuous integration pipeline
#   refactor: restructure code for better readability
#   perf: optimize data processing for speed
#   chore: update dependencies and clean up
#   revert: undo previous commit due to issues
#   style: apply code formatting and style fixes
#   build: update build scripts for new environment

## Git Integration Conventions (for code parsing commit messages)
# - All commit message parsing expects format: `title (#PR_NUMBER)`
# - Extract PR numbers using regex: `r'\(#(\d+)\)'`
# - GitHub repo is always: `https://github.com/ai-dynamo/dynamo`
# - Use full SHA for GitHub URLs, short SHA (7-9 chars) for display
#
# Example: Extract PR number from commit message
# ```python
# import re
# first_line = commit.message.split('\n')[0] if commit.message else ""
# pr_match = re.search(r'\(#(\d+)\)', first_line)
# if pr_match:
#     pr_number = pr_match.group(1)
#     pr_link = f"https://github.com/ai-dynamo/dynamo/pull/{pr_number}"
# ```

# =============================================================================
# COMMON CODE PATTERNS (dynamo-utils specific)
# =============================================================================

## Terminal Width Detection
# Use the common.py utility for terminal width detection with fallback:
# ```python
# from common import get_terminal_width
#
# width = get_terminal_width()
# # Fallback to 80 if detection fails
# ```

# =============================================================================
# Slack Request For Review (RFR) TEMPLATE
# =============================================================================
# - When asked to generate "RFR":
# - Output in the following format. Make sure the line counts are correct.
# - Make sure the <PR#NUMBER> is filled out and ask if it is unknown.
# - For possible reviewers, look at past commits and look for past committers to the files I modified.
# - If there is 0 document line changed, then don't print "documents: ..." section.
# - Never, ever show the literal text `<PR#NUMBER>`. If unsure what that is, ask me for it.
```
RFR (code: +123/-55 lines, documents: 50 lines changed):
*feat:* DIS-123 some feature desc here
*PR:* http://github.com/ai-dynamo/dynamo/pull/<PR#NUMBER>
*Reviewers:* <add possible reviewer login like @ryan, based on who last committed the files I editted>
```
# - Then, insert 3 very terse bullets about the PR
# - The output should be terse, in plain text, and surrounded by the triple-backquote chars (```) so that special #### characters are escaped.

# =============================================================================
# GITHUB PR DESCRIPTION TEMPLATE
# =============================================================================
# - When asked to generate a "GitHub PR Desc", look at the chain of continuous previous git commits from the same user/login (me, the author).
# - Then, use the following template to output a GitHub PR Description (aka "github pr"), in plain text.
# - The output should be terse, in plain text, and surrounded by the triple-backquote chars (```) so that special #### characters are escaped.
```
#### Overview:

<!-- Describe your pull request here, based on your commits. Terse, no more than 3 sentences, but 2 is better. -->

#### Details:

<!-- Describe the changes made in this PR, in bullet -->

#### Where should the reviewer start?

<!-- call out specific files that should be looked at closely -->

#### Related Issues: (use one of the action keywords Closes / Fixes / Resolves / Relates to)

<!-- put in Linear ticket here, like DIS-123 or DYN-789, by extracting the Linear ticket number from commit messages, if possible. If there is nothing, then leave this field blank. -->

/coderabbit profile chill
```
# - Again, output in plain-text-- do NOT add formatting, because I want to see the quadriple pound signs (e.g. "#### Something Here:")

# =============================================================================
# DOCKER AND DEPLOYMENT
# =============================================================================
# - Use multi-stage builds for smaller images
# - Set appropriate user permissions
# - Use .dockerignore to exclude unnecessary files
# - Pin dependency versions for reproducibility

# Example Dockerfile pattern:
```
FROM rust:1.70 as builder
WORKDIR /app
COPY . .
RUN cargo build --release

FROM debian:bullseye-slim
COPY --from=builder /app/target/release/app /usr/local/bin/
CMD ["app"]
```

# =============================================================================
# PERFORMANCE AND OPTIMIZATION
# =============================================================================
# - Profile before optimizing
# - Use appropriate data structures for the use case
# - Consider memory allocation patterns
# - Use async/await for I/O operations
# - Cache expensive computations when appropriate
# - Monitor resource usage in production

# =============================================================================
# SECURITY CONSIDERATIONS
# =============================================================================
# - Never commit API keys or secrets
# - Use environment variables for configuration
# - Validate all user inputs
# - Use parameterized queries for database operations
# - Follow principle of least privilege

# =============================================================================
# DOCUMENTATION STANDARDS
# =============================================================================
# Always add comments for:
# - Complex algorithms
# - Business logic
# - API endpoints
# - Configuration options
# - Non-obvious code decisions

# Use clear, concise comments that explain "why" not "what"
# Bad: "Loop through items" (obvious from code)
# Good: "Process items in batches to avoid memory issues"

# Using bullshit (BS) jargons
# **DO NOT ** use the following BS jargon words in documentations nor comments: intuitive, comprehensive, optimal, seamless, next-generation, holistic, cutting-edge.

# =============================================================================
# SPHINX DOCUMENTATION SYSTEM
# =============================================================================

## Overview
# The project uses Sphinx for documentation generation from markdown files.
# - Documentation source: `docs/` directory
# - Build output: `docs/build/html/`
# - Main script: `docs/generate_docs.py`

## Documentation Generation
# To build the documentation:
```
cd ~/dynamo
python docs/generate_docs.py
```

# The script performs three steps:
# 1. `make clean` - Clean previous builds
# 2. `preprocess_docs()` - Smart hyperlink conversion (see below)
# 3. `make html` - Build HTML with Sphinx

## Required Dependencies
# Install Sphinx and dependencies:
```
pip install sphinx sphinx-rtd-theme myst-parser
```

## Smart Hyperlink Conversion
# The `docs/generate_docs.py` script automatically converts links:
# - **GitHub URLs ‚Üí Relative paths**: For .md files in docs/, converts full GitHub URLs to relative paths
#   Example: `https://github.com/ai-dynamo/dynamo/blob/main/docs/guides/metrics.md` ‚Üí `../../guides/metrics.md`
# - **Relative paths ‚Üí GitHub URLs**: For non-.md files or paths outside docs/, converts to full GitHub URLs
#   Example: `../examples/config.pbtxt` ‚Üí `https://github.com/ai-dynamo/dynamo/blob/main/examples/config.pbtxt`
# This ensures docs work in both Sphinx HTML and when viewed on GitHub.

## Adding New Documentation Files
# When adding new .md files to the docs/ directory:
# 1. Place the file in the appropriate subdirectory (e.g., `docs/backends/*/`)
# 2. **Add to toctree**: Add the file path to `docs/hidden_toctree.rst` (for backend docs not in main TOC)
#    Example: `backends/sglang/prometheus.md`
# 3. Use relative paths like `../../guides/metrics.md` (script will handle conversion)
# 4. Test the build: `python docs/generate_docs.py`

## Toctree Structure
# - `docs/index.rst` - Main documentation index
# - `docs/_sections/*.rst` - Section indexes (backends, architecture, etc.)
# - `docs/hidden_toctree.rst` - Hidden toctree for files not in main TOC (backend docs, API reference, etc.)
# - Backend docs order in `hidden_toctree.rst`:
#   - TensorRT-LLM docs
#   - SGLang docs
#   - vLLM docs

## Build Warnings
# Sphinx runs with `-W` flag (warnings treated as errors):
# - Missing toctree entries cause build failures
# - All .md files in docs/ must be referenced in a toctree
# - Check build output for: `WARNING: document isn't included in any toctree`

## Exclusions
# Files/directories in `docs/exclusions.txt` are skipped during hyperlink conversion.

# =============================================================================
# DEBUGGING AND TROUBLESHOOTING
# =============================================================================
# - Use appropriate logging levels (debug, info, warn, error)
# - Add context to error messages
# - Use structured logging when possible
# - Include relevant stack traces for errors
# - Document common issues and solutions

# =============================================================================
# CODE REVIEW GUIDELINES
# =============================================================================
# - Review for security vulnerabilities
# - Check for performance issues
# - Ensure proper error handling
# - Verify test coverage
# - Look for code duplication
# - Check adherence to project conventions
