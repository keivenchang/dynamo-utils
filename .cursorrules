Cursor Rules for Dynamo Project
https://github.com/keivenchang/dynamo-utils/blob/main/.cursorrules

=============================================================================
TABLE OF CONTENTS
=============================================================================
1. AI PERSONALITY AND DOCUMENTATION GUIDELINES
  1.1 AI Personality
  1.2 Documentation Guidelines
  1.3 Forbidden Jargon

2. BEST PRACTICES
  2.1 Security
  2.2 Performance and Optimization
  2.3 UNIX Command Execution and Workflow
    2.3.1 Command Chaining
    2.3.2 Long-Running Programs
    2.3.3 Piping and Filtering
  2.4 Cron
    2.4.1 Environment and Variables
    2.4.2 Locks and Logging
    2.4.3 Editing crontab Safely
  2.5 Environment Awareness and Setup
    2.5.1 Virtualenv Activation (Host Machine Only)
    2.5.2 Docker Environment
      2.5.2.1 Setting umask for Group-Writable Permissions in Dockerfiles
      2.5.2.2 Example Dockerfile

3. UNIVERSAL CODE STYLE
  3.1 Emojis
  3.2 License Headers
  3.3 General Rules
  3.4 Rust Development
    3.4.1 Code Style
    3.4.2 File Organization
    3.4.3 Build Commands
    3.4.4 Type Inference for Examples
    3.4.5 Type Inference for lib/bindings/python
    3.4.6 Testing
    3.4.7 Error Handling
    3.4.8 Mutability Patterns
    3.4.9 Lock Management
    3.4.10 Dependency Management
    3.4.11 Python Bindings and Wheel Creation
  3.5 Python Development
    3.5.1 Code Style
    3.5.2 File Organization
    3.5.3 Error Handling
    3.5.4 Testing
  3.6 JavaScript/TypeScript
  3.7 Common Code Patterns
    3.7.1 Terminal Width Detection

4. UNIX/SHELL COMMANDS
  4.1 General Rules
  4.2 File Operations
  4.3 Permissions
  4.4 Path Display
  4.5 Pre-commit

5. GIT WORKFLOW
  5.1 Review Before Git Operations
  5.2 Merge Conflicts
  5.3 Commit Process
  5.4 Commit Message Format
  5.5 Git Integration (for parsing commit messages)

6. COMMUNICATION TEMPLATES AND CODE REVIEW
  6.1 Slack RFR Template
    6.1.1 GitHub to Slack Login Mappings
  6.2 GitHub PR Description Template
  6.3 Code Review Guidelines

7. DOCUMENTATION BUILD AND CI CHECKS
  7.1 Sphinx Documentation
    7.1.1 Overview
    7.1.2 Build Documentation
    7.1.3 Dependencies
    7.1.4 Smart Hyperlink Conversion
    7.1.5 Adding New Files
    7.1.6 Toctree Structure
    7.1.7 Build Warnings
    7.1.8 Checking Documentation Build
    7.1.9 Exclusions
  7.2 Pre-Merge CI Checks
    7.2.1 Rust Format Check
    7.2.2 Rust Clippy Checks
    7.2.3 Rust Tests
    7.2.4 Pre-commit Hooks
    7.2.5 Copyright Headers
    7.2.6 Cargo Deny (License Checks)
    7.2.7 Quick Pre-Commit Checklist

=============================================================================
1. AI PERSONALITY AND DOCUMENTATION GUIDELINES
=============================================================================

## 1.1 AI Personality
- Be direct, matter-of-fact, and honest about technical challenges
- Don't be overly agreeable or sycophantic
- Suggest alternatives when current approach has issues
- Ask clarifying questions when requirements are unclear
- CRITICAL: When debugging or fixing code, FIRST check what exists in main branch
  - Remove any extra tests/code that weren't in main or explicitly requested
  - Don't waste time debugging things that shouldn't exist
  - Only work on what was explicitly asked for
- Reproduce with a single concrete input (one job id / one log file / one failing command) before generalizing.
- Before changing code, re-read the exact region you‚Äôre editing; keep edits tightly scoped to avoid stale-context patch failures.

## 1.2 Documentation Guidelines
Always add comments for:
- Complex algorithms
- Business logic
- API endpoints
- Configuration options
- Non-obvious code decisions

Explain "why" not "what"
- Bad: "Loop through items" (obvious)
- Good: "Process items in batches to avoid memory issues"

## 1.3 Forbidden Jargon
DO NOT use these BS words in docs/comments:
- intuitive, comprehensive, optimal, seamless
- next-generation, holistic, cutting-edge

=============================================================================
2. BEST PRACTICES
=============================================================================

## 2.1 Security
- Never commit API keys or secrets
- Use environment variables for config
- Validate all user inputs
- Use parameterized queries for databases
- Follow principle of least privilege

## 2.2 Performance and Optimization
- Profile before optimizing
- Use appropriate data structures
- Consider memory allocation patterns
- Use async/await for I/O
- Cache expensive computations
- Monitor resource usage in production

## 2.3 UNIX Command Execution and Workflow

### 2.3.1 Command Chaining
- Chain multiple commands in one go whenever possible using && or ;
- Use parentheses for grouping: (a && b); (c || d)
- Examples:
  - cd dir && command
  - cmd1; cmd2; cmd3
  - (cd dir1 && cargo fmt); (cd dir2 && cargo fmt)
- Reduces latency and improves efficiency
- Be careful with shell quoting in long one-liners (especially nested quotes). Prefer simpler, verifiable commands (or write a small script) over clever quoting.

### 2.3.2 Long-Running Programs
- For long-running programs (vllm, sglang, trtllm), use tee to log output to a file and background it
- Do NOT filter output using grep - everything must be visible in the log file
- Format: program args 2>&1 | tee /tmp/program.log &
- Example: vllm serve 2>&1 | tee /tmp/vllm.log &
- Prefer a stable filename (same path) so it‚Äôs easy to `tail -f` (e.g. `/tmp/output1.log`)
- This allows monitoring while keeping the terminal responsive
- Do NOT use `-it` in scripts/background jobs (non-interactive runs will fail with `the input device is not a TTY`)
- If you want to `tail -f`, write to a stable log path (e.g. `/tmp/output1.log`) and tail that file (don‚Äôt invent per-run filenames unless requested)

### 2.3.3 Piping and Filtering
**CRITICAL BEST PRACTICE: For long-running or expensive commands, ALWAYS capture the full, unprocessed output first (to a temp file) and only filter that saved file afterward.**

**Correct pattern (ALWAYS use this):**
```bash
command > /tmp/output.txt 2>&1 &
# or for interactive monitoring:
command 2>&1 | tee /tmp/output.txt &
```

**ABSOLUTE RULES:**
- ‚úÖ **DO:** Redirect the ENTIRE, UNPROCESSED output to a temp file (or `tee` it)
- ‚úÖ **DO:** Background long-running commands with `&`
- ‚úÖ **DO:** Capture both stdout and stderr with `2>&1`
- ‚ùå **NEVER:** Pipe the output of long-running/expensive commands into `grep`, `head`, `tail`, or similar filters
- ‚ùå **NEVER:** Lose information by filtering before saving the full output

**Why:**
- Run the command ONCE and analyze the full output multiple times
- Preserves ALL information - no data loss
- Allows multiple different analyses on the saved file
- You can grep/head/tail the temp file without re-running the command

**Examples:**
- `docker ps -a > /tmp/containers.txt` ‚úÖ (NOT `docker ps -a | grep something` ‚ùå)
- `cargo test > /tmp/test.txt 2>&1 &` ‚úÖ (NOT `cargo test | grep PASS` ‚ùå)
- `kubectl get pods > /tmp/pods.txt` ‚úÖ (NOT `kubectl get pods | head -20` ‚ùå)
- Don‚Äôt assume tools exist (e.g. `rg`). Prefer Cursor search/`grep`; if an external binary is needed, check for it first (`command -v rg`).

When reviewing saved logs, filter out unimportant cargo test output (on the saved file, not the live command output):
- Example: `grep -v -E "running 0 tests|test result: ok\\. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out|tower_http::trace::on_failure:" /tmp/test.txt`
- "running 0 tests"
- "test result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out"
- "tower_http::trace::on_failure:"

## 2.4 Cron

### 2.4.1 Environment and Variables
- Cron does **not** source `~/.bashrc` by default. If you need tokens, source an explicit env file or use `bash -lc '...'`.
- Cron runs with a minimal environment; do not assume variables like `USER` exist.
  - If scripts use `set -u`, never reference `$USER` directly; use a fallback (`${USER:-${LOGNAME:-$(id -un)}}`).
- Cron variable assignments are **not a full shell**:
  - Avoid relying on nested expansion like `DYNAMO_UTILS=$NVIDIA_HOME/...`.
  - Avoid relying on `$HOME` expansion inside assignments.
  - Prefer absolute paths in the crontab for anything critical.

### 2.4.2 Locks and Logging
- If a cron job skips due to a lock, print a warning (stderr) with the lock path. Silent skips look like ‚Äúcron isn‚Äôt running‚Äù.
- Prefer stable, dated log directories so you can prove ‚Äúcron ran‚Äù by checking mtimes and tailing files.

### 2.4.3 Editing crontab Safely
- Cron path edits: `crontab -l` often contains literal strings like `$HOME/...` (not expanded). When replacing paths, match the literal text, then verify with `crontab -l | grep`.
- Avoid overly clever one-liner awk/sed edits to crontab; write the transform to a temp file or script so quoting doesn‚Äôt break and you can diff the output.

## 2.5 Environment Awareness and Setup
- Prefer robust behavior under bad environments:
  - Handle ‚Äúpoisoned‚Äù env vars/tokens deterministically (don‚Äôt silently pick the wrong credential source).
  - Keep core diagnostic modules runnable via a small CLI so you can test on a single file quickly.

### 2.5.1 Virtualenv Activation (Host Machine Only)
- At the start of each context, check if on host machine (not in Docker)
- If on host: activate the project venv (path varies by machine); if inside Docker, it's already activated.
- This ensures pre-commit and other Python tools are available
- Detection: Check if running in container by looking for /.dockerenv or checking hostname
- When debugging "a generated HTML page is not showing/updating in the browser":
  - Verify the on-disk file exists, permissions, and timestamp: `ls -lah <file> && stat <file> && head -n 10 <file>`
  - Confirm your web server docroot matches the filesystem path you‚Äôre editing (URL path ‚â† filesystem path).
  - If you regenerate output but still see old content, hard refresh / bypass cache, and verify mtime changed.
  - If grepping generated HTML, remember it may contain escaped text (e.g. `"` becomes `&quot;`), so match the escaped form or inspect the raw log.
  - If ‚Äúit worked earlier‚Äù, verify you‚Äôre not looking at a cached artifact: check mtimes and any cache index/state the generator uses.

### 2.5.2 Docker Environment
- Multi-stage builds for smaller images
- Set appropriate user permissions
- Use .dockerignore
- Pin dependency versions
- When one script delegates to another (e.g. build wrappers), do not re-derive values in the callee; pass through the computed values for parity.
- For BuildKit features, remember named contexts (`--build-context name=path`): missing passthrough can cause `COPY --from=<name>` to try pulling an image.

#### 2.5.2.1 Setting umask for Group-Writable Permissions in Dockerfiles

To create group-writable files/directories (775/664) in Dockerfiles:

**Global umask for RUN commands:**
```dockerfile
USER myuser
# Set umask globally for all subsequent RUN commands
RUN mkdir -p /etc/profile.d && echo 'umask 002' > /etc/profile.d/00-umask.sh
SHELL ["/bin/bash", "-l", "-o", "pipefail", "-c"]

# Now all RUN commands automatically use umask 002
RUN mkdir /test  # Creates drwxrwxr-x (775)
RUN touch /file  # Creates -rw-rw-r-- (664)
```

**CRITICAL: COPY does NOT respect umask!**
- The `COPY` instruction bypasses shell umask and always creates destination directories with 755
- The `--chmod` flag on COPY only affects contents, NOT the destination directory itself
- You MUST use explicit `chmod g+w` after COPY to fix the destination directory

Pattern for COPY with group-writable permissions:
```dockerfile
COPY --chmod=775 --chown=user:0 /source /dest
RUN chmod g+w /dest  # Required! COPY ignores umask and creates /dest as 755
```

Summary:
- ‚úÖ umask works for: RUN mkdir, RUN touch, pip install output files, etc.
- ‚ùå umask does NOT work for: COPY destination directories
- Solution: Use both umask (for RUN) and explicit chmod (after COPY)

#### 2.5.2.2 Example Dockerfile
```
FROM rust:1.70 as builder
WORKDIR /app
COPY . .
RUN cargo build --release

FROM debian:bullseye-slim
COPY --from=builder /app/target/release/app /usr/local/bin/
CMD ["app"]
```

#### 2.5.2.3 Container Permission Optimization (runtime/dev/local-dev)

Key rules (learned from debugging slow builds + permission issues):
- Terminology (be precise):
  - **Stages** refer to Dynamo container build targets: `--target` (e.g. `runtime`, `dev`, `local-dev`).
  - **Frameworks** refer to the LLM engine selection: `--framework` (same thing), typically one of: `none`, `vllm`, `sglang`, `trtllm`.
- Avoid recursive chmod/chown on large trees (e.g. `chmod -R g+w /workspace`, `chown -R ...`) ‚Äî they can add minutes.
- Prefer targeted, non-recursive permission fixes for the minimal runtime-writable directories:
  - `/home/dynamo` (user home)
  - `/home/dynamo/.cache` (uv/pip cache)
  - `/opt/dynamo` (runtime scratch files like `.launch_screen`)
  - `/workspace` (workspace writability)
- Use a three-tier container approach when possible:
  - `runtime`: production, minimal permissions, runs as `dynamo`
  - `dev`: development with extra tools, often root (use with caution)
  - `local-dev`: maps to host UID/GID for local development
- Always sanity-check permission changes:
  - For **runtime** images: `sanity_check.py --runtime-check-only --thorough`
  - For **dev/local-dev** images: `sanity_check.py --thorough`
- Monitor build times when adding permission operations; treat them as performance-sensitive code.

=============================================================================
3. UNIVERSAL CODE STYLE
=============================================================================

## 3.1 Emojis
- DO NOT use emojis (unprofessional)
- Rare exceptions only: ‚úÖ üö´ ‚ùå ‚ö†Ô∏è

## 3.2 License Headers
- Use first 2 lines only:
```
// SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
// SPDX-License-Identifier: Apache-2.0
```

## 3.3 General Rules
- Don't remove TODO comments or commented lines below them
- Don't generate *.md files unless explicitly requested
- Verify HTML/markdown links work before adding them
- When editing via apply-patch: hunks must be top-to-bottom ordered and match current file context; if a patch fails, re-read the relevant region and re-apply with narrower, accurate context (don‚Äôt guess line blocks).

## 3.4 Rust Development

### 3.4.1 Code Style
- snake_case for variables/functions
- PascalCase for types/traits
- Use explicit types when it improves readability
- Add doc comments (///) for public APIs
- Prefer tracing::error over eprintln
- Prefer shorter references: `MyStuff` instead of `crate::my_service::MyStuff`
- Prefer .to_string() over format!() when possible
- Prefer positive if/else: `if x then A else B` not `if !x then B else A`
  - Exception: `if !x then A` (without else) is fine
- Use debug_assert* over assert*

### 3.4.2 File Organization
- lib.rs: Library entry point
- mod.rs: Module definitions
- Separate files per module
- Tests: tests/ directory or inline with #[cfg(test)]

### 3.4.3 Build Commands
- Always use --locked: cargo test --locked, cargo build --locked, cargo install --locked
- Development build: cargo build --locked --features dynamo-llm/block-manager --workspace
- Clean builds: cargo clean
- Before commit: cargo fmt (run on all affected directories)
- See section 7.2 (Pre-Merge CI Checks) for comprehensive build/test/lint commands

### 3.4.4 Type Inference for Examples
Add to top-level Cargo.toml [workspace] members (REMOVE BEFORE COMMIT):
```
======== AUTO ADDED FOR TYPE-INFERENCE, SHOULD BE REMOVED BEFORE COMMIT ========
"lib/runtime/examples/system_metrics",
"lib/runtime/examples/hello_world",
"lib/runtime/examples/service_metrics",
"lib/bindings/python",
======== AUTO ADDED FOR TYPE-INFERENCE, SHOULD BE REMOVED BEFORE COMMIT ========
```

### 3.4.5 Type Inference for lib/bindings/python
1. Add "lib/bindings/python" to top-level Cargo.toml [workspace] members (see above)
3. Comment out [workspace] in lib/bindings/python/Cargo.toml:
```
======== WORKSPACE DECLARATION REMOVED FOR TYPE-INFERENCE, RESTORE BEFORE COMMIT ========
[workspace]
# empty workspace to exclude from top level workspace
# excluded due to pyo3 extension module build issues
======== WORKSPACE DECLARATION REMOVED FOR TYPE-INFERENCE, RESTORE BEFORE COMMIT ========
```
4. Add empty integration feature to lib/bindings/python/Cargo.toml (if not present):
```
[features]
default = []
block-manager = ["dynamo-llm/block-manager", "dep:dlpark", "dep:cudarc"]
integration = []  # Empty feature for rust-analyzer compatibility
```
5. Restart rust-analyzer (Cmd/Ctrl+Shift+P ‚Üí "Rust Analyzer: Restart Server")
6. IMPORTANT: Restore all changes before committing

### 3.4.6 Testing
- Write unit tests in same file (unless told otherwise)
- Use #[cfg(test)] for test-only code
- Mock external dependencies when mocks are available
- Integration tests use --features integration: cargo test --locked --features integration -- --nocapture
- Specific integration test: cargo test --locked -p dynamo-runtime --features integration --lib http_server -- --nocapture
- During tests, show progress if building/compiling
- List which tests failed (up to 10) and pass/fail breakdown (unit vs integration)
- For DistributedRuntime/Runtime/drt tests: use unique names (ns515, comp515, ep515)
  - See lib/runtime/src/metrics.rs for examples

### 3.4.7 Error Handling
- Use Result<T, E> for fallible operations
- Use Option<T> for nullable values
- Prefer ? operator over match for error propagation
- Use anyhow for application-level errors
```
pub fn process_data(data: &str) -> Result<ProcessedData, anyhow::Error> {
    let parsed = parse_input(data)?;
    let result = transform_data(parsed)?;
    Ok(result)
}
```

### 3.4.8 Mutability Patterns
Limit scope of mutable variables:
```
// Instead of:
let mut mut_var = ...;
mut_var.some_mutable_operation();
// ... mut_var used all over

// Do this:
let var = {
    let mut mut_var = ...;
    mut_var.some_mutable_operation();
    mut_var
};
```

### 3.4.9 Lock Management
Release locks before long operations:
```
// Bad:
let reg = self.registry.lock().unwrap();
if let Some(entry) = reg.get(name) {
    entry.execute_long_call()  // holds lock too long
}

// Good:
let long_call = {
    let reg = self.registry.lock().unwrap();
    reg.get(name).clone()
}; // Lock released here
long_call()
```

### 3.4.10 Dependency Management
Validate dependency updates:
```
cargo-deny --version || cargo install --locked cargo-deny@0.16.4
cargo-deny --no-default-features check --hide-inclusion-graph licenses bans --config deny.toml
```

### 3.4.11 Python Bindings and Wheel Creation
After changes in lib/bindings/python/rust/*:
1. cd lib/bindings/python && maturin develop --uv
3. Or use _/compile.sh shortcut (handles full build workflow)

Notes:
- `maturin develop` may update `Cargo.lock` if the dependency graph/features require it.
- Decide intentionally: allow lockfile updates for local iteration, or require locked builds (`--locked`) and commit the lockfile update once.

## 3.5 Python Development

### 3.5.1 Code Style
- Follow PEP 8
- Put imports at top of file (not inside functions)
- Check indentation carefully (must be perfect)
- Use dataclass for dicts with >4 elements (better type inference)
- Use simple regex for multi-line string manipulations
- snake_case for variables/functions
- PascalCase for classes
- Add type hints where beneficial
- Use docstrings for functions/classes
- Before commit: run mypy and precommit ruff
- 3+ print statements: use triple quotes """ ... """
- Outside Docker: source ~/bin/$(uname).$(uname -m)/venv.3.*/bin/activate

### 3.5.2 File Organization
- __init__.py for package initialization
- Clear module separation
- Tests in tests/ directory

### 3.5.3 Error Handling
Regex / parsing changes (common source of subtle bugs):
- Be very careful with escaping:
  - In Python raw strings, `\s` is whitespace; `\\s` is a literal backslash + `s` (often wrong).
- When changing a critical regex, add a tiny local one-line reproduction/‚Äúunit test‚Äù to prove the match works on representative input.
```
def process_file(filename: str) -> None:
    try:
        with open(filename, 'r') as f:
            data = f.read()
        process_data(data)
    except FileNotFoundError:
        logger.error(f"File {filename} not found")
        raise
```

### 3.5.4 Testing
- Framework: pytest
- Unit tests in tests/ directory
- Use fixtures for common setup
- Mock external services
- Always use: pytest --basetemp=/tmp/pytest_temp tests/

## 3.6 JavaScript/TypeScript
- camelCase for variables/functions
- PascalCase for components/classes
- Prefer const over let, avoid var
- Use async/await over .then() chains
- Add JSDoc comments for complex functions

## 3.7 Common Code Patterns

### 3.7.1 Terminal Width Detection
```
from common import get_terminal_width
width = get_terminal_width()  # Fallback to 80 if detection fails
```

=============================================================================
4. UNIX/SHELL COMMANDS
=============================================================================

## 4.1 General Rules
- Source .bashrc when shell starts (interactive shells). Cron jobs do **not** load `~/.bashrc` unless you explicitly source it.
- Never use "!" inside shell quotes
- No trailing spaces/tabs on empty lines
- Use proper quoting to prevent word splitting/globbing

## 4.2 File Operations
- Check if file is under git before moving
- Use git mv for tracked files, mv for untracked
- Delete *.lock files instead of stashing
- Do not edit `.gitignore` unless explicitly requested (prefer leaving local-only scripts untracked or placing them under `/tmp/`)
- Dedup safely: use hashes/diffs + reference search before deleting duplicates.
- Symlinks: do **not** create ‚Äúconvenience‚Äù symlinks by default (they clutter). Only add symlinks when explicitly requested or when a stable link is truly required for compatibility.
- When moving scripts, preserve history with `git mv`, ensure executable bits survive (`chmod +x`), and run a quick smoke test.

## 4.3 Permissions
```
USER_ID=$(stat -c "%u" .)
GROUP_ID=$(stat -c "%g" .)

# üö® DO NOT DO THIS:
# NEVER run recursive permission fixes on large trees (very slow, and easy to break things):
#   chown -R $USER_ID:$GROUP_ID .
#
# Prefer targeted, non-recursive fixes on only the specific directories you need writable.
# Examples:
#   chown $USER_ID:$GROUP_ID /path/to/dir
#   chown $USER_ID:$GROUP_ID /path/to/file
#   find /path/to/dir -maxdepth 1 -type d -name 'target' -exec chown $USER_ID:$GROUP_ID {} \;
```

- If you add a new `.sh` script that is meant to be executed, ensure it has a shebang and is executable (`chmod +x`) before committing.
- Permission-aware discovery: when scanning the filesystem (repos, logs, etc.), gate on permissions (e.g. world `r+x`) so dashboards don‚Äôt try to traverse private dirs.

## 4.4 Path Display
- Use tilde (~) instead of full paths: ~/path not /home/ubuntu/path

## 4.5 Pre-commit
ALWAYS run pre-commit checks before committing:
- For single file: pre-commit run --files <file_path>
- For all changed files: pre-commit run --all-files
- Pre-commit runs automatically on git commit, but run manually to catch issues early
- Fix any issues reported before committing

=============================================================================
5. GIT WORKFLOW
=============================================================================

## 5.1 Review Before Git Operations
Periodically review this .cursorrules before git operations
- Don‚Äôt assume the current working directory is a git repo. Confirm repo root first (`git rev-parse --show-toplevel`) or use `git -C <dir> ...` for the intended repo.

## 5.2 Git Interactive Editors
- Git commands like `git rebase --continue`, `git commit --amend`, and `git rebase -i` launch interactive text editors (vim/nano)
- Cursor does NOT have interactive editor
- Therefore ALWAYS use `GIT_EDITOR=true` prefix to bypass interactive editors:
  - `GIT_EDITOR=true git rebase --continue` - accepts default commit message
  - `GIT_EDITOR=true git commit --amend -m "message"` - amends with new message
  - For commits, use `-m "message"` flag instead of letting editor open
- If editor opens accidentally, the command will hang waiting for user input
- Example: `git rebase --continue` will open vim ‚Üí use `GIT_EDITOR=true git rebase --continue` instead

## 5.3 Merge Conflicts
After resolving:
1. git add <resolved_files>
   - You MUST `git add` each conflict-resolved file to mark it as resolved (merge/rebase/cherry-pick).
   - Forgetting to `git add` after conflict resolution will cause the operation to fail or repeat conflicts.
2. If in rebase: use `GIT_EDITOR=true git rebase --continue` (never let vim open)
3. Run cargo fmt on directories

## 5.4 Commit Process
- NEVER launch vim or any editor (always provide -m flag with message)
- Don‚Äôt suggest committing unless the user explicitly says to commit.
- Never commit top-level Cargo.toml or Cargo.lock (unless explicitly told)
- Never use --no-verify
- Signoff rules:
  - In dynamo-utils repository: --signoff is NOT required
  - In dynamo* repositories and /workspace: ALWAYS use --signoff (never skip it)
- Run cargo fmt before committing Rust changes
- Never add untracked files (unless explicitly told)
- List untracked files separately from modified files
- Prompt to git add modified files
- Scope commits when asked: keep reorganizations, code changes, and docs changes as separate commits.
- **BEFORE writing commit message:** Check `git log --oneline origin/main..HEAD`
  - Empty output = FIRST commit = Use verbose format with prefix
  - Shows commits = SUBSEQUENT commit = Use terse format without prefix
- Diff changes and generate appropriate message based on commit position
- For merge commits: use git commit -m "Merge ..." or git commit --no-edit

## 5.5 Commit Message Format

**CRITICAL: Determine commit type BEFORE writing the message**
1. Check if branch has existing commits: `git log --oneline origin/main..HEAD`
2. If output is EMPTY ‚Üí This is the FIRST commit ‚Üí Use INITIAL format
3. If output shows commits ‚Üí This is a SUBSEQUENT commit ‚Üí Use SUBSEQUENT format

### FIRST/INITIAL COMMIT (when branch has NO commits yet)
**Format:** Verbose with category prefix (feat:, fix:, docs:, etc.)
**Length:** Full descriptive sentence
**Examples:**
- feat: add new user authentication system
- fix: resolve memory leak in data processing
- docs: update API documentation
- test: add unit tests for user module
- ci: configure continuous integration pipeline
- refactor: reuse code for better maintenance and readability
- perf: optimize data processing for speed
- chore: update dependencies and clean up
- revert: undo previous commit due to issues
- style: apply code formatting and style fixes
- build: update build scripts for new environment

### SUBSEQUENT COMMITS (when branch ALREADY has commits)
**Format:** Terse, no prefix, straight to the point
**Length:** 1 line preferred, 2 lines maximum
**Examples:**
- Quick fix of the module in XYZ
- Documentation updates on XYZ
- Minor changing the usage of XYZ
- Renaming of XYZ to ZYX
- Remove leftover merge conflict marker
- Fix linting errors
- Address review comments
- Update test assertions

**DO NOT DO (subsequent commits):**
- ‚ùå Use category prefixes (save these for the FIRST commit):
  - feat: ...
  - fix: ...
  - refactor: ...
- ‚ùå Use WIP / placeholder messages:
  - WIP
  - tmp
  - stuff
- ‚ùå Write a multi-paragraph commit message (put details in the PR description instead)
- ‚ùå Restate the entire PR purpose (the FIRST commit already does that)

**Why this matters:** The first commit establishes the PR's primary purpose and shows up in git history. Subsequent commits are implementation details that get squashed during merge.

## 5.6 Git Integration (for parsing commit messages)
- Format: `title (#PR_NUMBER)`
- Extract PR: r'\(#(\d+)\)'
- GitHub repo: https://github.com/ai-dynamo/dynamo
- Use full SHA for URLs, short SHA (7-9 chars) for display

=============================================================================
6. COMMUNICATION TEMPLATES AND CODE REVIEW
=============================================================================

## 6.1 Slack RFR Template
Example output format (fill <PR#NUMBER>, verify line counts, map GitHub to Slack logins). If <PR#NUMBER> is unknown, ask.
```
RFR (code: +123/-55 lines, documents: 50 lines changed):
*feat:* DIS-3456 some feature desc here
*PR:* http://github.com/ai-dynamo/dynamo/pull/<PR#NUMBER>
*Reviewers:* <top 3 reviewers based on past commits>, @Ryan McCormick, ...
```
Then add 3 terse bullets about the PR
Output in plain text surrounded by triple backticks

### 6.1.1 GitHub to Slack Login Mappings
- rmccormick -> @Ryan McCormick
- kthui -> @Jacky Hui
- nv-tusharma, tusharma ‚Üí @Tushar Sharma
- ishandhanani ‚Üí @Ishan Dhanani
- anant-s ‚Üí @Anant Sharma
- hhzhang16 ‚Üí @Hannah Zhang
- grahamk ‚Üí @Graham King
- krish ‚Üí @Krishnan Prashanth
- yanrpei ‚Üí @Rudy Pei
- biswa.panda ‚Üí @Biswa Ranjan Panda
- tedzhouhk ‚Üí @Hongkuan Zhou
- tzulingk ‚Üí @Tzu-Ling Kan
- neelays ‚Üí @Neelay Shah
- tanmayv25 ‚Üí @Tanmay Verma

If 0 document lines changed, omit "documents: ..." section
Never show literal <PR#NUMBER>, ask if unknown

## 6.2 GitHub PR Description Template
Look at chain of continuous commits from same author
Output in plain text surrounded by triple backticks (no formatting):
```
#### Overview:

<!-- 2-3 terse sentences based on commits -->

#### Details:

<!-- Bullet points describing changes -->

#### Where should the reviewer start?

<!-- Specific files to review closely -->

#### Related Issues: (use Closes / Fixes / Resolves / Relates to)

<!-- Linear ticket (DIS-1123, DYN-1789, OPS-4321) extracted from commits, or leave blank -->

/coderabbit profile chill
```

## 6.3 Code Review Guidelines
- Review for security vulnerabilities
- Check for performance issues
- Ensure proper error handling
- Verify test coverage
- Look for code duplication
- Check adherence to conventions

- When providing review feedback, prefer short, direct, conversational paragraphs.
- Output in plain text surrounded by triple backticks (no formatting).
- For structural changes (like big code refactors, Dockerfiles, shared build scripts, or cross-file patterns), call out both:
  - what the author did well and why it works (or what it enables), and
  - disadvantages, if any (e.g. complexity, readability, maintainability)
- For shared/duplicated sections that must stay in sync across files (e.g., `dynamo_base`, `wheel_builder`, `dynamo_runtime` in `Dockerfile.{vllm,trtllm,sglang}`), explicitly suggest:
  - adding comments near those sections noting they must stay synchronized, and
  - considering templating instead of code-duplication to avoid code drift and maintenance nightmare
- It's preferred to phrase colloquial feedback like this:
  - "Hey Dillon, thank you for restructuring the framework Dockerfiles to use that same dynamo_base, dynamo_runtime, and wheel_builder flow so that various pieces are built once and then reused/cached later."
  - "You may want to put a big comment in shared targets (e.g. dynamo_base, wheel_builder, dynamo_runtime, etc), saying that they need to be in-sync between all the Dockerfile.{vllm,trtllm,sglang} files. Otherwise, somebody is going to get lazy, modify only one file, and mess something up. Definitely look into templating."
  - "The tradeoff to optimization is that the stage graph is now pretty hard to follow. I find it really hard to follow this code now, unless I ask AI to give me a dependency/flow chart like the one below. Maybe we could add the dependency/flow chart next to the code, for better understanding. The AI can sync it up pretty easily."
  - "Looking forward to get this in, it will be good to have ..."

=============================================================================
7. DOCUMENTATION BUILD AND CI CHECKS
=============================================================================

## 7.1 Sphinx Documentation

### 7.1.1 Overview
- Source: docs/ directory
- Build output: docs/build/html/
- Main script: docs/generate_docs.py

### 7.1.2 Build Documentation
```
cd ~/dynamo
python docs/generate_docs.py
```
Steps: make clean ‚Üí preprocess_docs() ‚Üí make html

### 7.1.3 Dependencies
```
pip install sphinx sphinx-rtd-theme myst-parser
```

### 7.1.4 Smart Hyperlink Conversion
docs/generate_docs.py converts links automatically:
- GitHub URLs ‚Üí relative paths (for .md files in docs/)
  Example: https://github.com/ai-dynamo/dynamo/blob/main/docs/guides/metrics.md ‚Üí ../../guides/metrics.md
- Relative paths ‚Üí GitHub URLs (for non-.md or outside docs/)
  Example: ../examples/config.pbtxt ‚Üí https://github.com/ai-dynamo/dynamo/blob/main/examples/config.pbtxt

### 7.1.5 Adding New Files
1. Place file in appropriate subdirectory (docs/backends/*)
3. Add to docs/hidden_toctree.rst (for backend docs not in main TOC)
   Example: backends/sglang/prometheus.md
4. Use relative paths (script handles conversion)
5. Test: python docs/generate_docs.py

### 7.1.6 Toctree Structure
- docs/index.rst: Main index
- docs/_sections/*.rst: Section indexes
- docs/hidden_toctree.rst: Hidden toctree for files not in main TOC
- Backend docs order: TensorRT-LLM, SGLang, vLLM

### 7.1.7 Build Warnings
Sphinx uses -W flag (warnings = errors)
- Missing toctree entries cause failures
- All .md files must be referenced in a toctree
- Check for: "WARNING: document isn't included in any toctree"
- Invalid JSON in code blocks marked as ```json will cause lexer errors
  - Either fix JSON syntax (remove ellipsis ..., comments, etc.)
  - Or change to ```text if non-valid JSON content is intentional

### 7.1.8 Checking Documentation Build
Test locally before pushing (replicates CI environment):
```
cd /path/to/dynamo/repo
docker build -t docs-builder -f container/Dockerfile.docs .
```
Expected: "build succeeded" with no warnings
If fails: Check for missing images, broken links, invalid JSON in code blocks

### 7.1.9 Exclusions
Files in docs/exclusions.txt are skipped during hyperlink conversion

## 7.2 Pre-Merge CI Checks
Run all the checks that CI runs before merging. These commands replicate the
CI environment locally.

Quick checklist before commit:
1. cargo fmt (in all affected directories)
2. cargo clippy --no-deps --all-targets -- -D warnings
3. cargo test --locked --all-targets
4. pre-commit run --all-files (if Python changes)

### 7.2.1 Rust Format Check
Check code formatting (must pass before commit):

cargo fmt -- --check

Check all directories that CI checks:
(cd . && cargo fmt -- --check)
(cd lib/bindings/python && cargo fmt -- --check)
(cd lib/runtime/examples && cargo fmt -- --check)
(cd launch/dynamo-run && cargo fmt -- --check)

Fix formatting:
cargo fmt

### 7.2.2 Rust Clippy Checks
Find unused imports, warnings, and other issues:

cargo clippy --no-deps --all-targets -- -D warnings

Check all directories that CI checks:
(cd . && cargo clippy --no-deps --all-targets -- -D warnings)
(cd lib/bindings/python && cargo clippy --no-deps --all-targets -- -D warnings)
(cd lib/runtime/examples && cargo clippy --no-deps --all-targets -- -D warnings)
(cd launch/dynamo-run && cargo clippy --no-deps --all-targets -- -D warnings)

Find specific issues:
cargo clippy --no-deps --all-targets -- -D warnings > /tmp/clippy.txt 2>&1
grep -B 5 -A 10 "unused import" /tmp/clippy.txt
grep -E "^(error|warning)" /tmp/clippy.txt

### 7.2.3 Rust Tests
Run all tests (unit, doc, integration):

Compile tests first (separate build from execution):
cargo test --locked --no-run

Run doc tests (CI runs doc generation first):
cargo doc --no-deps && cargo test --locked --doc

Run unit tests (--all-targets doesn't run doc tests):
cargo test --locked --all-targets

NOTE: CI runs tests in these directories: ., lib/bindings/python, lib/runtime/examples, launch/dynamo-run

Backend E2E serve tests (aggregated, single-GPU):

pytest tests/serve/ -k "aggregated and not disagg" -v --tb=short

Note: Avoid using -k "aggregated" alone because it also matches "disaggregated".
Always use the combined filter "aggregated and not disagg" so only aggregated tests run.

### 7.2.4 Pre-commit Hooks
Run all pre-commit hooks (Python linting, formatting, etc.):

pre-commit run --all-files
pre-commit run --files path/to/file.py
pre-commit run ruff --all-files
pre-commit run mypy --all-files

Common hooks: ruff (Python linter), mypy (type checking), trailing-whitespace,
end-of-file-fixer, check-yaml, check-json

### 7.2.5 Copyright Headers
Check copyright headers (requires PowerShell):

pwsh .github/workflows/copyright-check.ps1

Or manually check:
grep -L "SPDX-FileCopyrightText" $(find . -name "*.rs" -o -name "*.py" -o -name "*.go")

### 7.2.6 Cargo Deny (License Checks)
Check licenses and security advisories:

cargo-deny --version || cargo install cargo-deny@0.16.4
cargo-deny --no-default-features check --hide-inclusion-graph licenses bans --config deny.toml

### 7.2.7 Quick Pre-Commit Checklist
Before committing Rust changes, run:
1. cargo fmt
2. cargo clippy --no-deps --all-targets -- -D warnings
3. cargo test --locked --all-targets
4. pre-commit run --all-files  (if Python changes)
5. If scripts or HTML generators changed: `python3 -m py_compile <touched_py_files>` and run the relevant generator/update script to validate end-to-end output.

Expected result: All checks pass with no errors

